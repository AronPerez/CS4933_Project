{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iJk5dwX4LJNg",
        "V9nHcs8503-k",
        "G7AjDhlq1YwV",
        "9EEgGNvIJ7hh",
        "I7RzZHDXTV8e",
        "r6C-SGESYa0j"
      ],
      "history_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPyT9wlaFotm1Vthb6PsXKU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AronPerez/CS4933_Project/blob/aaron/CV_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYWG4t9bDsJb"
      },
      "source": [
        "# Initial "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaCzvQgnxV3Z"
      },
      "source": [
        "## Aarons workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugjlyN850yz5"
      },
      "source": [
        "### Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY6QQAlxLXTj",
        "outputId": "9ca0927d-23ad-4898-fe4e-8c448dfe50a0"
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GP73R4ExU9F"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import pickle\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from scipy.misc import imread\n",
        "from abc import abstractmethod\n",
        "from __future__ import print_function\n",
        "from torchsummary import summary\n",
        "import torch"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F2PRK-h8quW",
        "outputId": "f0038651-4115-46dc-9210-d8c7faebdff3"
      },
      "source": [
        "# Prompt for input\n",
        "name = input(\"Select a model name \")\n",
        "while True:\n",
        "  dataset = input(\"Select a dataset, either places365_dataset or cifar10_dataset \")\n",
        "  if \"PLACES365\" in dataset.upper():\n",
        "    dataset = 'PLACE365_DATASET'\n",
        "    dataset_path = './dataset/places365'\n",
        "    break\n",
        "  elif 'CIFAR10' in dataset.upper():\n",
        "    dataset = 'CIFAR10_DATASET'\n",
        "    dataset_path = './dataset/cifar10'\n",
        "    break\n",
        "  else:\n",
        "    print(\"Invalid dataset\")\n",
        "  \n",
        "batch_size = int(input(\"Please select a batch size \"))\n",
        "\n",
        "options = {\n",
        "    \"seed\": 100,\n",
        "    \"beta1\": 0.0,\n",
        "    \"name\": name.upper(),\n",
        "    \"mode\": 0,\n",
        "    \"dataset\": dataset,\n",
        "    \"dataset_path\": dataset_path,\n",
        "    \"checkpoints_path\": './checkpoints',\n",
        "    \"color_space\": 'lab',\n",
        "    \"batch_size\": batch_size,\n",
        "    \"l1_weight\": 100.0,\n",
        "    \"lr\": 3e-4,\n",
        "    \"lr_decay\": True,\n",
        "    \"lr_decay_rate\": 0.1,\n",
        "    \"lr_decay_steps\": 1e4,\n",
        "    \"augment\": True,\n",
        "    \"acc_thresh\": 2.0,\n",
        "    \"gpu_ids\": 0,\n",
        "    \"save\": True,\n",
        "    \"save_interval\": 1000,\n",
        "    \"sample\": True,\n",
        "    \"sample_size\": 8,\n",
        "    \"sample_interval\": 1000,\n",
        "    \"validate\": False,\n",
        "    \"validate_interval\": 0,\n",
        "    \"log\": True,\n",
        "    \"log_interval\": 10,\n",
        "    \"visualize\": True,\n",
        "    \"visualize_window\": 100,\n",
        "    \"test_input\": '',\n",
        "    \"test_output\": '',\n",
        "    \"turing_test_size\": 100,\n",
        "    \"turing_test_delay\": 0,\n",
        "    \"label_smoothing\": 1,\n",
        "    \"training\": True\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select a model name Morty\n",
            "Select a dataset, either places365_dataset or cifar10_dataset cifar10_dataset\n",
            "Please select a batch size 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJk5dwX4LJNg"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP4_iitzL57G"
      },
      "source": [
        "CIFAR10_DATASET = 'cifar10'\n",
        "PLACES365_DATASET = 'places365'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "munjCgoxLKzA"
      },
      "source": [
        "class BaseDataset():\n",
        "    def __init__(self, name, path, training=True, augment=True):\n",
        "        self.name = name\n",
        "        self.augment = augment and training\n",
        "        self.training = training\n",
        "        self.path = path\n",
        "        self._data = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __iter__(self):\n",
        "        total = len(self)\n",
        "        start = 0\n",
        "\n",
        "        while start < total:\n",
        "            item = self[start]\n",
        "            start += 1\n",
        "            yield item\n",
        "\n",
        "        raise StopIteration\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        val = self.data[index]\n",
        "        try:\n",
        "            img = imread(val) if isinstance(val, str) else val\n",
        "\n",
        "            # grayscale images\n",
        "            if np.sum(img[:,:,0] - img[:,:,1]) == 0 and np.sum(img[:,:,0] - img[:,:,2]) == 0:\n",
        "                return None\n",
        "\n",
        "            if self.augment and np.random.binomial(1, 0.5) == 1:\n",
        "                img = img[:, ::-1, :]\n",
        "\n",
        "        except:\n",
        "            img = None\n",
        "\n",
        "        return img\n",
        "\n",
        "    def generator(self, batch_size, recusrive=False):\n",
        "        start = 0\n",
        "        total = len(self)\n",
        "\n",
        "        while True:\n",
        "            while start < total:\n",
        "                end = np.min([start + batch_size, total])\n",
        "                items = []\n",
        "\n",
        "                for ix in range(start, end):\n",
        "                    item = self[ix]\n",
        "                    if item is not None:\n",
        "                        items.append(item)\n",
        "\n",
        "                start = end\n",
        "                yield items\n",
        "\n",
        "            if recusrive:\n",
        "                start = 0\n",
        "\n",
        "            else:\n",
        "                raise StopIteration\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        if len(self._data) == 0:\n",
        "            self._data = self.load()\n",
        "            np.random.shuffle(self._data)\n",
        "\n",
        "        return self._data\n",
        "\n",
        "    @abstractmethod\n",
        "    def load(self):\n",
        "        return []"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-4QgxFVL-In"
      },
      "source": [
        "class Cifar10Dataset(BaseDataset):\n",
        "    def __init__(self, path, training=True, augment=True):\n",
        "        super(Cifar10Dataset, self).__init__(CIFAR10_DATASET, path, training, augment)\n",
        "\n",
        "    def load(self):\n",
        "        data = []\n",
        "        if self.training:\n",
        "            for i in range(1, 6):\n",
        "                filename = '{}/data_batch_{}'.format(self.path, i)\n",
        "                batch_data = unpickle(filename)\n",
        "                if len(data) > 0:\n",
        "                    data = np.vstack((data, batch_data[b'data']))\n",
        "                else:\n",
        "                    data = batch_data[b'data']\n",
        "\n",
        "        else:\n",
        "            filename = '{}/test_batch'.format(self.path)\n",
        "            batch_data = unpickle(filename)\n",
        "            data = batch_data[b'data']\n",
        "\n",
        "        w = 32\n",
        "        h = 32\n",
        "        s = w * h\n",
        "        data = np.array(data)\n",
        "        data = np.dstack((data[:, :s], data[:, s:2 * s], data[:, 2 * s:]))\n",
        "        data = data.reshape((-1, w, h, 3))\n",
        "        return data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9nHcs8503-k"
      },
      "source": [
        "### Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcsc9ogM0HWy"
      },
      "source": [
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise ('Boolean value expected.')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGA96OFazXZO"
      },
      "source": [
        "def parse(input):\n",
        "  opt = input\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_ids\n",
        "  opt.color_space = opt.color_space.upper()\n",
        "  opt.training = opt.mode == 1\n",
        "\n",
        "  if opt.seed == 0:\n",
        "    opt.seed = random.randint(0, 2**31 - 1)\n",
        "\n",
        "  if opt.dataset_path == './dataset':\n",
        "    opt.dataset_path += ('/' + opt.dataset)\n",
        "\n",
        "  if opt.checkpoints_path == './checkpoints':\n",
        "    opt.checkpoints_path += ('/' + opt.dataset)\n",
        "\n",
        "    return opt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7AjDhlq1YwV"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9F-MP9bJe5v"
      },
      "source": [
        "def stitch_images(grayscale, original, pred):\n",
        "    gap = 5\n",
        "    width, height = original[0][:, :, 0].shape\n",
        "    img_per_row = 2 if width > 200 else 4\n",
        "    img = Image.new('RGB', (width * img_per_row * 3 + gap * (img_per_row - 1), height * int(len(original) / img_per_row)))\n",
        "\n",
        "    grayscale = np.array(grayscale).squeeze()\n",
        "    original = np.array(original)\n",
        "    pred = np.array(pred)\n",
        "\n",
        "    for ix in range(len(original)):\n",
        "        xoffset = int(ix % img_per_row) * width * 3 + int(ix % img_per_row) * gap\n",
        "        yoffset = int(ix / img_per_row) * height\n",
        "        im1 = Image.fromarray(grayscale[ix])\n",
        "        im2 = Image.fromarray(original[ix])\n",
        "        im3 = Image.fromarray((pred[ix] * 255).astype(np.uint8))\n",
        "        img.paste(im1, (xoffset, yoffset))\n",
        "        img.paste(im2, (xoffset + width, yoffset))\n",
        "        img.paste(im3, (xoffset + width + width, yoffset))\n",
        "\n",
        "    return img\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEE0LX0PJfnW"
      },
      "source": [
        "def create_dir(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    return dir"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlLFjIcBJfg0"
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_RoZnlEJfZK"
      },
      "source": [
        "def moving_average(data, window_width):\n",
        "    cumsum_vec = np.cumsum(np.insert(data, 0, 0))\n",
        "    ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
        "    return ma_vec"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLckq20lJfQG"
      },
      "source": [
        "def imshow(img, title=''):\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.set_window_title(title)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation='none')\n",
        "    plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTAqlwtdJsTy"
      },
      "source": [
        "def imsave(img, path):\n",
        "    im = Image.fromarray(np.array(img).astype(np.uint8).squeeze())\n",
        "    im.save(path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39WEh-A7JsiN"
      },
      "source": [
        "def turing_test(real_img, fake_img, delay=0):\n",
        "    height, width, _ = real_img.shape\n",
        "    imgs = np.array([real_img, (fake_img * 255).astype(np.uint8)])\n",
        "    real_index = np.random.binomial(1, 0.5)\n",
        "    fake_index = (real_index + 1) % 2\n",
        "\n",
        "    img = Image.new('RGB', (2 + width * 2, height))\n",
        "    img.paste(Image.fromarray(imgs[real_index]), (0, 0))\n",
        "    img.paste(Image.fromarray(imgs[fake_index]), (2 + width, 0))\n",
        "\n",
        "    img.success = 0\n",
        "\n",
        "    def onclick(event):\n",
        "        if event.xdata is not None:\n",
        "            if event.x < width and real_index == 0:\n",
        "                img.success = 1\n",
        "\n",
        "            elif event.x > width and real_index == 1:\n",
        "                img.success = 1\n",
        "\n",
        "        plt.gcf().canvas.stop_event_loop()\n",
        "\n",
        "    plt.ion()\n",
        "    plt.gcf().canvas.mpl_connect('button_press_event', onclick)\n",
        "    plt.title('click on the real image')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation='none')\n",
        "    plt.show()\n",
        "    plt.draw()\n",
        "    plt.gcf().canvas.start_event_loop(delay)\n",
        "\n",
        "    return img.success"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90FAEkHoJsyl"
      },
      "source": [
        "def visualize(train_log_file, test_log_file, window_width, title=''):\n",
        "    train_data = np.loadtxt(train_log_file)\n",
        "    test_data = np.loadtxt(test_log_file)\n",
        "\n",
        "    if len(train_data.shape) < 2:\n",
        "        return\n",
        "\n",
        "    if len(train_data) < window_width:\n",
        "        window_width = len(train_data) - 1\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.set_window_title(title)\n",
        "\n",
        "    plt.ion()\n",
        "    plt.subplot('121')\n",
        "    plt.cla()\n",
        "    if len(train_data) > 1:\n",
        "        plt.plot(moving_average(train_data[:, 8], window_width))\n",
        "    plt.title('train')\n",
        "\n",
        "    plt.subplot('122')\n",
        "    plt.cla()\n",
        "    if len(test_data) > 1:\n",
        "        plt.plot(test_data[:, 8])\n",
        "    plt.title('test')\n",
        "\n",
        "    plt.show()\n",
        "    plt.draw()\n",
        "    plt.pause(.01)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EEgGNvIJ7hh"
      },
      "source": [
        "### Ops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNh-LQlFKDmi"
      },
      "source": [
        "COLORSPACE_RGB = 'RGB'\n",
        "COLORSPACE_LAB = 'LAB'\n",
        "#tf.nn.softmax_cross_entropy_with_logits_v2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDFVi6SYKAkM"
      },
      "source": [
        "def conv2d(inputs, filters, name, kernel_size=4, strides=2, bnorm=True, activation=None, seed=None):\n",
        "    \"\"\"\n",
        "    Creates a conv2D block\n",
        "    \"\"\"\n",
        "    initializer=tf.variance_scaling_initializer(seed=seed)\n",
        "    res = tf.layers.conv2d(\n",
        "        name=name,\n",
        "        inputs=inputs,\n",
        "        filters=filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=initializer)\n",
        "\n",
        "    if bnorm:\n",
        "        res = tf.layers.batch_normalization(inputs=res, name='bn_' + name, training=True)\n",
        "\n",
        "    # activation after batch-norm\n",
        "    if activation is not None:\n",
        "        res = activation(res)\n",
        "\n",
        "    return res"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5d84dahKAeM"
      },
      "source": [
        "def conv2d_transpose(inputs, filters, name, kernel_size=4, strides=2, bnorm=True, activation=None, seed=None):\n",
        "    \"\"\"\n",
        "    Creates a conv2D-transpose block\n",
        "    \"\"\"\n",
        "    initializer=tf.variance_scaling_initializer(seed=seed)\n",
        "    res = tf.layers.conv2d_transpose(\n",
        "        name=name,\n",
        "        inputs=inputs,\n",
        "        filters=filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=initializer)\n",
        "\n",
        "    if bnorm:\n",
        "        res = tf.layers.batch_normalization(inputs=res, name='bn_' + name, training=True)\n",
        "\n",
        "    # activation after batch-norm\n",
        "    if activation is not None:\n",
        "        res = activation(res)\n",
        "\n",
        "    return res"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ1K6xBEKAYw"
      },
      "source": [
        "def pixelwise_accuracy(img_real, img_fake, colorspace, thresh):\n",
        "    \"\"\"\n",
        "    Measures the accuracy of the colorization process by comparing pixels\n",
        "    \"\"\"\n",
        "    img_real = postprocess(img_real, colorspace, COLORSPACE_LAB)\n",
        "    img_fake = postprocess(img_fake, colorspace, COLORSPACE_LAB)\n",
        "\n",
        "    diffL = tf.abs(tf.round(img_real[..., 0]) - tf.round(img_fake[..., 0]))\n",
        "    diffA = tf.abs(tf.round(img_real[..., 1]) - tf.round(img_fake[..., 1]))\n",
        "    diffB = tf.abs(tf.round(img_real[..., 2]) - tf.round(img_fake[..., 2]))\n",
        "\n",
        "    # within %thresh of the original\n",
        "    predL = tf.cast(tf.less_equal(diffL, 1 * thresh), tf.float64)        # L: [0, 100]\n",
        "    predA = tf.cast(tf.less_equal(diffA, 2.2 * thresh), tf.float64)      # A: [-110, 110]\n",
        "    predB = tf.cast(tf.less_equal(diffB, 2.2 * thresh), tf.float64)      # B: [-110, 110]\n",
        "\n",
        "    # all three channels are within the threshold\n",
        "    pred = predL * predA * predB\n",
        "\n",
        "    return tf.reduce_mean(pred)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n-SkClBKASx"
      },
      "source": [
        "def preprocess(img, colorspace_in, colorspace_out):\n",
        "    if colorspace_out.upper() == COLORSPACE_RGB:\n",
        "        if colorspace_in == COLORSPACE_LAB:\n",
        "            img = lab_to_rgb(img)\n",
        "\n",
        "        # [0, 1] => [-1, 1]\n",
        "        img = (img / 255.0) * 2 - 1\n",
        "\n",
        "    elif colorspace_out.upper() == COLORSPACE_LAB:\n",
        "        if colorspace_in == COLORSPACE_RGB:\n",
        "            img = rgb_to_lab(img / 255.0)\n",
        "\n",
        "        L_chan, a_chan, b_chan = tf.unstack(img, axis=3)\n",
        "\n",
        "        # L: [0, 100] => [-1, 1]\n",
        "        # A, B: [-110, 110] => [-1, 1]\n",
        "        img = tf.stack([L_chan / 50 - 1, a_chan / 110, b_chan / 110], axis=3)\n",
        "\n",
        "    return img"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZcMVbpNKANL"
      },
      "source": [
        "def postprocess(img, colorspace_in, colorspace_out):\n",
        "    if colorspace_in.upper() == COLORSPACE_RGB:\n",
        "        # [-1, 1] => [0, 1]\n",
        "        img = (img + 1) / 2\n",
        "\n",
        "        if colorspace_out == COLORSPACE_LAB:\n",
        "            img = rgb_to_lab(img)\n",
        "\n",
        "    elif colorspace_in.upper() == COLORSPACE_LAB:\n",
        "        L_chan, a_chan, b_chan = tf.unstack(img, axis=3)\n",
        "\n",
        "        # L: [-1, 1] => [0, 100]\n",
        "        # A, B: [-1, 1] => [-110, 110]\n",
        "        img = tf.stack([(L_chan + 1) / 2 * 100, a_chan * 110, b_chan * 110], axis=3)\n",
        "\n",
        "        if colorspace_out == COLORSPACE_RGB:\n",
        "            img = lab_to_rgb(img)\n",
        "\n",
        "    return img"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n537DjJYKAFc"
      },
      "source": [
        "def rgb_to_lab(srgb):\n",
        "    # based on https://github.com/torch/image/blob/9f65c30167b2048ecbe8b7befdc6b2d6d12baee9/generic/image.c\n",
        "    with tf.name_scope(\"rgb_to_lab\"):\n",
        "        srgb_pixels = tf.reshape(srgb, [-1, 3])\n",
        "\n",
        "        with tf.name_scope(\"srgb_to_xyz\"):\n",
        "            linear_mask = tf.cast(srgb_pixels <= 0.04045, dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(srgb_pixels > 0.04045, dtype=tf.float32)\n",
        "            rgb_pixels = (srgb_pixels / 12.92 * linear_mask) + (((srgb_pixels + 0.055) / 1.055) ** 2.4) * exponential_mask\n",
        "            rgb_to_xyz = tf.constant([\n",
        "                #    X        Y          Z\n",
        "                [0.412453, 0.212671, 0.019334],  # R\n",
        "                [0.357580, 0.715160, 0.119193],  # G\n",
        "                [0.180423, 0.072169, 0.950227],  # B\n",
        "            ])\n",
        "            xyz_pixels = tf.matmul(rgb_pixels, rgb_to_xyz)\n",
        "\n",
        "        # https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
        "        with tf.name_scope(\"xyz_to_cielab\"):\n",
        "\n",
        "            # normalize for D65 white point\n",
        "            xyz_normalized_pixels = tf.multiply(xyz_pixels, [1 / 0.950456, 1.0, 1 / 1.088754])\n",
        "\n",
        "            epsilon = 6 / 29\n",
        "            linear_mask = tf.cast(xyz_normalized_pixels <= (epsilon**3), dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(xyz_normalized_pixels > (epsilon**3), dtype=tf.float32)\n",
        "            fxfyfz_pixels = (xyz_normalized_pixels / (3 * epsilon**2) + 4 / 29) * linear_mask + (xyz_normalized_pixels ** (1 / 3)) * exponential_mask\n",
        "\n",
        "            # convert to lab\n",
        "            fxfyfz_to_lab = tf.constant([\n",
        "                #  l       a       b\n",
        "                [0.0, 500.0, 0.0],  # fx\n",
        "                [116.0, -500.0, 200.0],  # fy\n",
        "                [0.0, 0.0, -200.0],  # fz\n",
        "            ])\n",
        "            lab_pixels = tf.matmul(fxfyfz_pixels, fxfyfz_to_lab) + tf.constant([-16.0, 0.0, 0.0])\n",
        "\n",
        "        return tf.reshape(lab_pixels, tf.shape(srgb))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4_LOFJUJ_3d"
      },
      "source": [
        "def lab_to_rgb(lab):\n",
        "    with tf.name_scope(\"lab_to_rgb\"):\n",
        "        lab_pixels = tf.reshape(lab, [-1, 3])\n",
        "\n",
        "        # https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
        "        with tf.name_scope(\"cielab_to_xyz\"):\n",
        "            # convert to fxfyfz\n",
        "            lab_to_fxfyfz = tf.constant([\n",
        "                #   fx      fy        fz\n",
        "                [1 / 116.0, 1 / 116.0, 1 / 116.0],  # l\n",
        "                [1 / 500.0, 0.0, 0.0],  # a\n",
        "                [0.0, 0.0, -1 / 200.0],  # b\n",
        "            ])\n",
        "            fxfyfz_pixels = tf.matmul(lab_pixels + tf.constant([16.0, 0.0, 0.0]), lab_to_fxfyfz)\n",
        "\n",
        "            # convert to xyz\n",
        "            epsilon = 6 / 29\n",
        "            linear_mask = tf.cast(fxfyfz_pixels <= epsilon, dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(fxfyfz_pixels > epsilon, dtype=tf.float32)\n",
        "            xyz_pixels = (3 * epsilon**2 * (fxfyfz_pixels - 4 / 29)) * linear_mask + (fxfyfz_pixels ** 3) * exponential_mask\n",
        "\n",
        "            # denormalize for D65 white point\n",
        "            xyz_pixels = tf.multiply(xyz_pixels, [0.950456, 1.0, 1.088754])\n",
        "\n",
        "        with tf.name_scope(\"xyz_to_srgb\"):\n",
        "            xyz_to_rgb = tf.constant([\n",
        "                #     r           g          b\n",
        "                [3.2404542, -0.9692660, 0.0556434],  # x\n",
        "                [-1.5371385, 1.8760108, -0.2040259],  # y\n",
        "                [-0.4985314, 0.0415560, 1.0572252],  # z\n",
        "            ])\n",
        "            rgb_pixels = tf.matmul(xyz_pixels, xyz_to_rgb)\n",
        "            # avoid a slightly negative number messing up the conversion\n",
        "            rgb_pixels = tf.clip_by_value(rgb_pixels, 0.0, 1.0)\n",
        "            linear_mask = tf.cast(rgb_pixels <= 0.0031308, dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(rgb_pixels > 0.0031308, dtype=tf.float32)\n",
        "            srgb_pixels = (rgb_pixels * 12.92 * linear_mask) + ((rgb_pixels ** (1 / 2.4) * 1.055) - 0.055) * exponential_mask\n",
        "\n",
        "        return tf.reshape(srgb_pixels, tf.shape(lab))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHwXO1oCTiiM"
      },
      "source": [
        "class Progbar(object):\n",
        "    \"\"\"Displays a progress bar.\n",
        "    Arguments:\n",
        "        target: Total number of steps expected, None if unknown.\n",
        "        width: Progress bar width on screen.\n",
        "        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n",
        "        stateful_metrics: Iterable of string names of metrics that\n",
        "            should *not* be averaged over time. Metrics in this list\n",
        "            will be displayed as-is. All others will be averaged\n",
        "            by the progbar before display.\n",
        "        interval: Minimum visual progress update interval (in seconds).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target, width=25, verbose=1, interval=0.05,\n",
        "                 stateful_metrics=None):\n",
        "        self.target = target\n",
        "        self.width = width\n",
        "        self.verbose = verbose\n",
        "        self.interval = interval\n",
        "        if stateful_metrics:\n",
        "            self.stateful_metrics = set(stateful_metrics)\n",
        "        else:\n",
        "            self.stateful_metrics = set()\n",
        "\n",
        "        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n",
        "                                  sys.stdout.isatty()) or\n",
        "                                 'ipykernel' in sys.modules or\n",
        "                                 'posix' in sys.modules)\n",
        "        self._total_width = 0\n",
        "        self._seen_so_far = 0\n",
        "        # We use a dict + list to avoid garbage collection\n",
        "        # issues found in OrderedDict\n",
        "        self._values = {}\n",
        "        self._values_order = []\n",
        "        self._start = time.time()\n",
        "        self._last_update = 0\n",
        "\n",
        "    def update(self, current, values=None):\n",
        "        \"\"\"Updates the progress bar.\n",
        "        Arguments:\n",
        "            current: Index of current step.\n",
        "            values: List of tuples:\n",
        "                `(name, value_for_last_step)`.\n",
        "                If `name` is in `stateful_metrics`,\n",
        "                `value_for_last_step` will be displayed as-is.\n",
        "                Else, an average of the metric over time will be displayed.\n",
        "        \"\"\"\n",
        "        values = values or []\n",
        "        for k, v in values:\n",
        "            if k not in self._values_order:\n",
        "                self._values_order.append(k)\n",
        "            if k not in self.stateful_metrics:\n",
        "                if k not in self._values:\n",
        "                    self._values[k] = [v * (current - self._seen_so_far),\n",
        "                                       current - self._seen_so_far]\n",
        "                else:\n",
        "                    self._values[k][0] += v * (current - self._seen_so_far)\n",
        "                    self._values[k][1] += (current - self._seen_so_far)\n",
        "            else:\n",
        "                self._values[k] = v\n",
        "        self._seen_so_far = current\n",
        "\n",
        "        now = time.time()\n",
        "        info = ' - %.0fs' % (now - self._start)\n",
        "        if self.verbose == 1:\n",
        "            if (now - self._last_update < self.interval and\n",
        "                    self.target is not None and current < self.target):\n",
        "                return\n",
        "\n",
        "            prev_total_width = self._total_width\n",
        "            if self._dynamic_display:\n",
        "                sys.stdout.write('\\b' * prev_total_width)\n",
        "                sys.stdout.write('\\r')\n",
        "            else:\n",
        "                sys.stdout.write('\\n')\n",
        "\n",
        "            if self.target is not None:\n",
        "                numdigits = int(np.floor(np.log10(self.target))) + 1\n",
        "                barstr = '%%%dd/%d [' % (numdigits, self.target)\n",
        "                bar = barstr % current\n",
        "                prog = float(current) / self.target\n",
        "                prog_width = int(self.width * prog)\n",
        "                if prog_width > 0:\n",
        "                    bar += ('=' * (prog_width - 1))\n",
        "                    if current < self.target:\n",
        "                        bar += '>'\n",
        "                    else:\n",
        "                        bar += '='\n",
        "                bar += ('.' * (self.width - prog_width))\n",
        "                bar += ']'\n",
        "            else:\n",
        "                bar = '%7d/Unknown' % current\n",
        "\n",
        "            self._total_width = len(bar)\n",
        "            sys.stdout.write(bar)\n",
        "\n",
        "            if current:\n",
        "                time_per_unit = (now - self._start) / current\n",
        "            else:\n",
        "                time_per_unit = 0\n",
        "            if self.target is not None and current < self.target:\n",
        "                eta = time_per_unit * (self.target - current)\n",
        "                if eta > 3600:\n",
        "                    eta_format = '%d:%02d:%02d' % (eta // 3600,\n",
        "                                                   (eta % 3600) // 60,\n",
        "                                                   eta % 60)\n",
        "                elif eta > 60:\n",
        "                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n",
        "                else:\n",
        "                    eta_format = '%ds' % eta\n",
        "\n",
        "                info = ' - ETA: %s' % eta_format\n",
        "            else:\n",
        "                if time_per_unit >= 1:\n",
        "                    info += ' %.0fs/step' % time_per_unit\n",
        "                elif time_per_unit >= 1e-3:\n",
        "                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n",
        "                else:\n",
        "                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n",
        "\n",
        "            for k in self._values_order:\n",
        "                info += ' - %s:' % k\n",
        "                if isinstance(self._values[k], list):\n",
        "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
        "                    if abs(avg) > 1e-3:\n",
        "                        info += ' %.4f' % avg\n",
        "                    else:\n",
        "                        info += ' %.4e' % avg\n",
        "                else:\n",
        "                    info += ' %s' % self._values[k]\n",
        "\n",
        "            self._total_width += len(info)\n",
        "            if prev_total_width > self._total_width:\n",
        "                info += (' ' * (prev_total_width - self._total_width))\n",
        "\n",
        "            if self.target is not None and current >= self.target:\n",
        "                info += '\\n'\n",
        "\n",
        "            sys.stdout.write(info)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        elif self.verbose == 2:\n",
        "            if self.target is None or current >= self.target:\n",
        "                for k in self._values_order:\n",
        "                    info += ' - %s:' % k\n",
        "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
        "                    if avg > 1e-3:\n",
        "                        info += ' %.4f' % avg\n",
        "                    else:\n",
        "                        info += ' %.4e' % avg\n",
        "                info += '\\n'\n",
        "\n",
        "                sys.stdout.write(info)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        self._last_update = now\n",
        "\n",
        "    def add(self, n, values=None):\n",
        "        self.update(self._seen_so_far + n, values)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7RzZHDXTV8e"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VjuibMyTa_T"
      },
      "source": [
        "class BaseModel:\n",
        "    def __init__(self, sess, options):\n",
        "        self.sess = sess\n",
        "        self.options = options\n",
        "        self.name = options[\"name\"]\n",
        "        self.samples_dir = os.path.join(options[\"checkpoints_path\"], 'samples')\n",
        "        self.test_log_file = os.path.join(options[\"checkpoints_path\"], 'log_test.dat')\n",
        "        self.train_log_file = os.path.join(options[\"checkpoints_path\"], 'log_train.dat')\n",
        "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "        self.dataset_train = self.create_dataset(True)\n",
        "        self.dataset_val = self.create_dataset(False)\n",
        "        self.sample_generator = self.dataset_val.generator(options[\"sample_size\"], True)\n",
        "        self.iteration = 0\n",
        "        self.epoch = 0\n",
        "        self.is_built = False\n",
        "\n",
        "    def train(self):\n",
        "        total = len(self.dataset_train)\n",
        "\n",
        "        for epoch in range(options.epochs):\n",
        "            lr_rate = self.sess.run(self.learning_rate)\n",
        "\n",
        "            print('Training epoch: %d' % (epoch + 1) + \" - learning rate: \" + str(lr_rate))\n",
        "\n",
        "            self.epoch = epoch + 1\n",
        "            self.iteration = 0\n",
        "\n",
        "            generator = self.dataset_train.generator(options[\"batch_size\"])\n",
        "            progbar = Progbar(total, width=25, stateful_metrics=['epoch', 'iter', 'step'])\n",
        "\n",
        "            for input_rgb in generator:\n",
        "                feed_dic = {self.input_rgb: input_rgb}\n",
        "\n",
        "                self.iteration = self.iteration + 1\n",
        "                self.sess.run([self.dis_train], feed_dict=feed_dic)\n",
        "                self.sess.run([self.gen_train, self.accuracy], feed_dict=feed_dic)\n",
        "                self.sess.run([self.gen_train, self.accuracy], feed_dict=feed_dic)\n",
        "\n",
        "                lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc, step = self.eval_outputs(feed_dic=feed_dic)\n",
        "\n",
        "                progbar.add(len(input_rgb), values=[\n",
        "                    (\"epoch\", epoch + 1),\n",
        "                    (\"iter\", self.iteration),\n",
        "                    (\"step\", step),\n",
        "                    (\"D loss\", lossD),\n",
        "                    (\"D fake\", lossD_fake),\n",
        "                    (\"D real\", lossD_real),\n",
        "                    (\"G loss\", lossG),\n",
        "                    (\"G L1\", lossG_l1),\n",
        "                    (\"G gan\", lossG_gan),\n",
        "                    (\"accuracy\", acc)\n",
        "                ])\n",
        "\n",
        "                # log model at checkpoints\n",
        "                if options[\"log\"] and step % options[\"log_interval\"] == 0:\n",
        "                    with open(self.train_log_file, 'a') as f:\n",
        "                        f.write('%d %d %f %f %f %f %f %f %f\\n' % (self.epoch, step, lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc))\n",
        "\n",
        "                    if options[\"visualize\"]:\n",
        "                        visualize(self.train_log_file, self.test_log_file, options[\"visualize_window\"], self.name)\n",
        "\n",
        "                # sample model at checkpoints\n",
        "                if options[\"sample\"] and step % options[\"sample_interval\"] == 0:\n",
        "                    self.sample(show=False)\n",
        "\n",
        "                # validate model at checkpoints\n",
        "                if options[\"validate\"] and options[\"validate_interval\"] > 0 and step % options[\"validate_interval\"] == 0:\n",
        "                    self.validate()\n",
        "\n",
        "                # save model at checkpoints\n",
        "                if options[\"save\"] and step % options[\"save_interval\"] == 0:\n",
        "                    self.save()\n",
        "\n",
        "            if options[\"validate\"]:\n",
        "                self.validate()\n",
        "\n",
        "    def validate(self):\n",
        "        print('\\n\\nValidating epoch: %d' % self.epoch)\n",
        "        total = len(self.dataset_val)\n",
        "        val_generator = self.dataset_val.generator(options[\"batch_size\"])\n",
        "        progbar = Progbar(total, width=25)\n",
        "\n",
        "        for input_rgb in val_generator:\n",
        "            feed_dic = {self.input_rgb: input_rgb}\n",
        "\n",
        "            self.sess.run([self.dis_loss, self.gen_loss, self.accuracy], feed_dict=feed_dic)\n",
        "\n",
        "            lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc, step = self.eval_outputs(feed_dic=feed_dic)\n",
        "\n",
        "            progbar.add(len(input_rgb), values=[\n",
        "                (\"D loss\", lossD),\n",
        "                (\"D fake\", lossD_fake),\n",
        "                (\"D real\", lossD_real),\n",
        "                (\"G loss\", lossG),\n",
        "                (\"G L1\", lossG_l1),\n",
        "                (\"G gan\", lossG_gan),\n",
        "                (\"accuracy\", acc)\n",
        "            ])\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    def test(self):\n",
        "        print('\\nTesting...')\n",
        "        dataset = TestDataset(options[\"test_input\"] or (options[\"checkpoints_path\"] + '/test'))\n",
        "        outputs_path = create_dir(options[\"test_output\"] or (options[\"checkpoints_path\"] + '/output'))\n",
        "\n",
        "        for index in range(len(dataset)):\n",
        "            img_gray_path, img_gray = dataset[index]\n",
        "            name = os.path.basename(img_gray_path)\n",
        "            path = os.path.join(outputs_path, name)\n",
        "\n",
        "            feed_dic = {self.input_gray: img_gray[None, :, :, None]}\n",
        "            outputs = self.sess.run(self.sampler, feed_dict=feed_dic)\n",
        "            outputs = postprocess(tf.convert_to_tensor(outputs), colorspace_in=options[\"color_space\"], colorspace_out=COLORSPACE_RGB).eval() * 255\n",
        "            print(path)\n",
        "            imsave(outputs[0], path)\n",
        "\n",
        "    def sample(self, show=True):\n",
        "        input_rgb = next(self.sample_generator)\n",
        "        feed_dic = {self.input_rgb: input_rgb}\n",
        "\n",
        "        step, rate = self.sess.run([self.global_step, self.learning_rate])\n",
        "        fake_image, input_gray = self.sess.run([self.sampler, self.input_gray], feed_dict=feed_dic)\n",
        "        fake_image = postprocess(tf.convert_to_tensor(fake_image), colorspace_in=options[\"color_space\"], colorspace_out=COLORSPACE_RGB)\n",
        "        img = stitch_images(input_gray, input_rgb, fake_image.eval())\n",
        "\n",
        "        create_dir(self.samples_dir)\n",
        "        sample = options[\"dataset\"] + \"_\" + str(step).zfill(5) + \".png\"\n",
        "\n",
        "        if show:\n",
        "            imshow(np.array(img), self.name)\n",
        "        else:\n",
        "            print('\\nsaving sample ' + sample + ' - learning rate: ' + str(rate))\n",
        "            img.save(os.path.join(self.samples_dir, sample))\n",
        "\n",
        "    def turing_test(self):\n",
        "        batch_size = options[\"batch_size\"]\n",
        "        gen = self.dataset_val.generator(batch_size, True)\n",
        "        count = 0\n",
        "        score = 0\n",
        "        size = options[\"turing_test_size\"]\n",
        "\n",
        "        while count < size:\n",
        "            input_rgb = next(gen)\n",
        "            feed_dic = {self.input_rgb: input_rgb}\n",
        "            fake_image = self.sess.run(self.sampler, feed_dict=feed_dic)\n",
        "            fake_image = postprocess(tf.convert_to_tensor(fake_image), colorspace_in=options[\"color_space\"], colorspace_out=COLORSPACE_RGB)\n",
        "\n",
        "            for i in range(np.min([batch_size, size - count])):\n",
        "                res = turing_test(input_rgb[i], fake_image.eval()[i], options[\"turing_test_delay\"])\n",
        "                count += 1\n",
        "                score += res\n",
        "                print('success: %d - fail: %d - rate: %f' % (score, count - score, (count - score) / count))\n",
        "\n",
        "    def build(self):\n",
        "        if self.is_built:\n",
        "            return\n",
        "        print(\"We're here??????\")\n",
        "        self.is_built = True\n",
        "\n",
        "        gen_factory = self.create_generator()\n",
        "        dis_factory = self.create_discriminator()\n",
        "        smoothing = 0.9 if options[\"label_smoothing\"] else 1\n",
        "        seed = options[\"seed\"]\n",
        "        kernel = 4\n",
        "\n",
        "        # model input placeholder: RGB imaege\n",
        "        self.input_rgb = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='input_rgb')\n",
        "        print(\"Fuck me\")\n",
        "        # model input after preprocessing: LAB image\n",
        "        self.input_color = preprocess(self.input_rgb, colorspace_in=COLORSPACE_RGB, colorspace_out=options[\"color_space\"])\n",
        "\n",
        "        # test mode: model input is a graycale placeholder\n",
        "        if options[\"mode\"] == 1:\n",
        "            self.input_gray = tf.placeholder(tf.float32, shape=(None, None, None, 1), name='input_gray')\n",
        "\n",
        "        # train/turing-test we extract grayscale image from color image\n",
        "        else:\n",
        "            self.input_gray = tf.image.rgb_to_grayscale(self.input_rgb)\n",
        "\n",
        "        gen = gen_factory.create(self.input_gray, kernel, seed)\n",
        "        dis_real = dis_factory.create(tf.concat([self.input_gray, self.input_color], 3), kernel, seed)\n",
        "        dis_fake = dis_factory.create(tf.concat([self.input_gray, gen], 3), kernel, seed, reuse_variables=True)\n",
        "\n",
        "        gen_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.ones_like(dis_fake))\n",
        "        dis_real_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_real, labels=tf.ones_like(dis_real) * smoothing)\n",
        "        dis_fake_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.zeros_like(dis_fake))\n",
        "\n",
        "        self.dis_loss_real = tf.reduce_mean(dis_real_ce)\n",
        "        self.dis_loss_fake = tf.reduce_mean(dis_fake_ce)\n",
        "        self.dis_loss = tf.reduce_mean(dis_real_ce + dis_fake_ce)\n",
        "\n",
        "        self.gen_loss_gan = tf.reduce_mean(gen_ce)\n",
        "        self.gen_loss_l1 = tf.reduce_mean(tf.abs(self.input_color - gen)) * options[\"l1_weight\"]\n",
        "        self.gen_loss = self.gen_loss_gan + self.gen_loss_l1\n",
        "\n",
        "        self.sampler = tf.identity(gen_factory.create(self.input_gray, kernel, seed, reuse_variables=True), name='output')\n",
        "        self.accuracy = pixelwise_accuracy(self.input_color, gen, options[\"color_space\"], options[\"acc_thresh\"])\n",
        "        self.learning_rate = tf.constant(options[\"lr\"])\n",
        "\n",
        "        # learning rate decay\n",
        "        if options[\"lr_decay\"] and options[\"lr_decay\"] > 0:\n",
        "            self.learning_rate = tf.maximum(1e-6, tf.train.exponential_decay(\n",
        "                learning_rate=options[\"lr\"],\n",
        "                global_step=self.global_step,\n",
        "                decay_steps=options[\"lr_decay_steps\"],\n",
        "                decay_rate=options[\"lr_decay_rate\"]))\n",
        "\n",
        "        # generator optimizaer\n",
        "        self.gen_train = tf.train.AdamOptimizer(\n",
        "            learning_rate=self.learning_rate,\n",
        "            beta1=options[\"beta1\"]\n",
        "        ).minimize(self.gen_loss, var_list=gen_factory.var_list)\n",
        "\n",
        "        # discriminator optimizaer\n",
        "        self.dis_train = tf.train.AdamOptimizer(\n",
        "            learning_rate=self.learning_rate / 10,\n",
        "            beta1=options[\"beta1\"]\n",
        "        ).minimize(self.dis_loss, var_list=dis_factory.var_list, global_step=self.global_step)\n",
        "\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "    def load(self):\n",
        "        ckpt = tf.train.get_checkpoint_state(options[\"checkpoints_path\"])\n",
        "        if ckpt is not None:\n",
        "            print('loading model...\\n')\n",
        "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "            self.saver.restore(self.sess, os.path.join(options[\"checkpoints_path\"], ckpt_name))\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def save(self):\n",
        "        print('saving model...\\n')\n",
        "        self.saver.save(self.sess, os.path.join(options[\"checkpoints_path\"], 'CGAN_' + options[\"dataset\"]), write_meta_graph=False)\n",
        "\n",
        "    def eval_outputs(self, feed_dic):\n",
        "        '''\n",
        "        evaluates the loss and accuracy\n",
        "        returns (D loss, D_fake loss, D_real loss, G loss, G_L1 loss, G_gan loss, accuracy, step)\n",
        "        '''\n",
        "        lossD_fake = self.dis_loss_fake.eval(feed_dict=feed_dic)\n",
        "        lossD_real = self.dis_loss_real.eval(feed_dict=feed_dic)\n",
        "        lossD = self.dis_loss.eval(feed_dict=feed_dic)\n",
        "\n",
        "        lossG_l1 = self.gen_loss_l1.eval(feed_dict=feed_dic)\n",
        "        lossG_gan = self.gen_loss_gan.eval(feed_dict=feed_dic)\n",
        "        lossG = lossG_l1 + lossG_gan\n",
        "\n",
        "        acc = self.accuracy.eval(feed_dict=feed_dic)\n",
        "        step = self.sess.run(self.global_step)\n",
        "\n",
        "        return lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc, step\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_generator(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_discriminator(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_dataset(self, training):\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZvxkLLZVEEK"
      },
      "source": [
        "class Cifar10Model(BaseModel):\n",
        "    def __init__(self, sess, options):\n",
        "        super(Cifar10Model, self).__init__(sess, options)\n",
        "\n",
        "    def create_generator(self):\n",
        "        kernels_gen_encoder = [\n",
        "            (64, 1, 0),     # [batch, 32, 32, ch] => [batch, 32, 32, 64]\n",
        "            (128, 2, 0),    # [batch, 32, 32, 64] => [batch, 16, 16, 128]\n",
        "            (256, 2, 0),    # [batch, 16, 16, 128] => [batch, 8, 8, 256]\n",
        "            (512, 2, 0),    # [batch, 8, 8, 256] => [batch, 4, 4, 512]\n",
        "            (512, 2, 0),    # [batch, 4, 4, 512] => [batch, 2, 2, 512]\n",
        "        ]\n",
        "\n",
        "        kernels_gen_decoder = [\n",
        "            (512, 2, 0.5),  # [batch, 2, 2, 512] => [batch, 4, 4, 512]\n",
        "            (256, 2, 0.5),  # [batch, 4, 4, 512] => [batch, 8, 8, 256]\n",
        "            (128, 2, 0),    # [batch, 8, 8, 256] => [batch, 16, 16, 128]\n",
        "            (64, 2, 0),     # [batch, 16, 16, 128] => [batch, 32, 32, 64]\n",
        "        ]\n",
        "\n",
        "        return Generator('gen', kernels_gen_encoder, kernels_gen_decoder, training=options[\"training\"])\n",
        "\n",
        "    def create_discriminator(self):\n",
        "        kernels_dis = [\n",
        "            (64, 2, 0),     # [batch, 32, 32, ch] => [batch, 16, 16, 64]\n",
        "            (128, 2, 0),    # [batch, 16, 16, 64] => [batch, 8, 8, 128]\n",
        "            (256, 2, 0),    # [batch, 8, 8, 128] => [batch, 4, 4, 256]\n",
        "            (512, 1, 0),    # [batch, 4, 4, 256] => [batch, 4, 4, 512]\n",
        "        ]\n",
        "\n",
        "        return Discriminator('dis', kernels_dis, training=options[\"training\"])\n",
        "\n",
        "    def create_dataset(self, training=True):\n",
        "        return Cifar10Dataset(\n",
        "            path=self.options[\"dataset_path\"],\n",
        "            training=training,\n",
        "            augment=self.options[\"augment\"])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6C-SGESYa0j"
      },
      "source": [
        "### Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxePEOwkYqCc"
      },
      "source": [
        "class Discriminator(object):\n",
        "    def __init__(self, name, kernels, training=True):\n",
        "        self.name = name\n",
        "        self.kernels = kernels\n",
        "        self.training = training\n",
        "        self.var_list = []\n",
        "\n",
        "    def create(self, inputs, kernel_size=None, seed=None, reuse_variables=None):\n",
        "        output = inputs\n",
        "        with tf.variable_scope(self.name, reuse=reuse_variables):\n",
        "            for index, kernel in enumerate(self.kernels):\n",
        "\n",
        "                # not use batch-norm in the first layer\n",
        "                bnorm = False if index == 0 else True\n",
        "                name = 'conv' + str(index)\n",
        "                output = conv2d(\n",
        "                    inputs=output,\n",
        "                    name=name,\n",
        "                    kernel_size=kernel_size,\n",
        "                    filters=kernel[0],\n",
        "                    strides=kernel[1],\n",
        "                    bnorm=bnorm,\n",
        "                    activation=tf.nn.leaky_relu,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                if kernel[2] > 0:\n",
        "                    keep_prob = 1.0 - kernel[2] if self.training else 1.0\n",
        "                    output = tf.nn.dropout(output, keep_prob=keep_prob, name='dropout_' + name, seed=seed)\n",
        "\n",
        "            output = conv2d(\n",
        "                inputs=output,\n",
        "                name='conv_last',\n",
        "                filters=1,\n",
        "                kernel_size=4,                  # last layer kernel size = 4\n",
        "                strides=1,                      # last layer stride = 1\n",
        "                bnorm=False,                    # do not use batch-norm for the last layer\n",
        "                seed=seed\n",
        "            )\n",
        "\n",
        "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
        "\n",
        "            return output"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbA0lbXAYsG-"
      },
      "source": [
        "class Generator(object):\n",
        "    def __init__(self, name, encoder_kernels, decoder_kernels, output_channels=3, training=True):\n",
        "        self.name = name\n",
        "        self.encoder_kernels = encoder_kernels\n",
        "        self.decoder_kernels = decoder_kernels\n",
        "        self.output_channels = output_channels\n",
        "        self.training = training\n",
        "        self.var_list = []\n",
        "\n",
        "    def create(self, inputs, kernel_size=None, seed=None, reuse_variables=None):\n",
        "        output = inputs\n",
        "\n",
        "        with tf.variable_scope(self.name, reuse=reuse_variables):\n",
        "\n",
        "            layers = []\n",
        "\n",
        "            # encoder branch\n",
        "            for index, kernel in enumerate(self.encoder_kernels):\n",
        "\n",
        "                name = 'conv' + str(index)\n",
        "                output = conv2d(\n",
        "                    inputs=output,\n",
        "                    name=name,\n",
        "                    kernel_size=kernel_size,\n",
        "                    filters=kernel[0],\n",
        "                    strides=kernel[1],\n",
        "                    activation=tf.nn.leaky_relu,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                # save contracting path layers to be used for skip connections\n",
        "                layers.append(output)\n",
        "                \n",
        "                if kernel[2] > 0:\n",
        "                    keep_prob = 1.0 - kernel[2] if self.training else 1.0\n",
        "                    output = tf.nn.dropout(output, keep_prob=keep_prob, name='dropout_' + name, seed=seed)\n",
        "\n",
        "            # decoder branch\n",
        "            for index, kernel in enumerate(self.decoder_kernels):\n",
        "\n",
        "                name = 'deconv' + str(index)\n",
        "                output = conv2d_transpose(\n",
        "                    inputs=output,\n",
        "                    name=name,\n",
        "                    kernel_size=kernel_size,\n",
        "                    filters=kernel[0],\n",
        "                    strides=kernel[1],\n",
        "                    activation=tf.nn.relu,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                if kernel[2] > 0:\n",
        "                    keep_prob = 1.0 - kernel[2] if self.training else 1.0\n",
        "                    output = tf.nn.dropout(output, keep_prob=keep_prob, name='dropout_' + name, seed=seed)\n",
        "\n",
        "                # concat the layer from the contracting path with the output of the current layer\n",
        "                # concat only the channels (axis=3)\n",
        "                output = tf.concat([layers[len(layers) - index - 2], output], axis=3)\n",
        "\n",
        "            output = conv2d(\n",
        "                inputs=output,\n",
        "                name='conv_last',\n",
        "                filters=self.output_channels,   # number of output chanels\n",
        "                kernel_size=1,                  # last layer kernel size = 1\n",
        "                strides=1,                      # last layer stride = 1\n",
        "                bnorm=False,                    # do not use batch-norm for the last layer\n",
        "                activation=tf.nn.tanh,          # tanh activation function for the output\n",
        "                seed=seed\n",
        "            )\n",
        "\n",
        "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
        "\n",
        "            return output"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSpIwxlX0yxn"
      },
      "source": [
        "### Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ngYKG5r5y15h",
        "outputId": "ab37b4fe-130d-4140-a4e4-88b5d68f49e2"
      },
      "source": [
        "# Driver\n",
        "\n",
        "# reset tensorflow graph\n",
        "tf.reset_default_graph()\n",
        "# initialize random seed\n",
        "tf.set_random_seed(options[\"seed\"])\n",
        "np.random.seed(options[\"seed\"])\n",
        "random.seed(options[\"seed\"])\n",
        "# create a session environment\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  if options[\"dataset\"] == 'CIFAR10_DATASET':\n",
        "    model = Cifar10Model(sess, options)\n",
        "\n",
        "  elif options[\"dataset\"] == 'PLACES365_DATASET':\n",
        "    model = Places365Model(sess, options)\n",
        "\n",
        "  if not os.path.exists(options[\"checkpoints_path\"]):\n",
        "    os.makedirs(options[\"checkpoints_path\"])\n",
        "\n",
        "  if options[\"log\"]:\n",
        "    open(model.train_log_file, 'w').close()\n",
        "    open(model.test_log_file, 'w').close()\n",
        "  # build the model and initialize\n",
        "  model.build()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  # load model only after global variables initialization\n",
        "  model.load()\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  #summary(model, (3, 512,1024))\n",
        "  print(model)\n",
        "\n",
        "  if options[\"mode\"] == 0:\n",
        "    args = options\n",
        "    print('\\n------------ Options -------------')\n",
        "    with open(os.path.join(options[\"checkpoints_path\"], 'options.dat'), 'w') as f:\n",
        "      for k, v in sorted(args.items()):\n",
        "        print('%s: %s' % (str(k), str(v)))\n",
        "        f.write('%s: %s\\n' % (str(k), str(v)))\n",
        "    print('-------------- End ----------------\\n') \n",
        "\n",
        "    model.train()\n",
        "      \n",
        "  elif options[\"mode\"] == 1:\n",
        "      model.test()\n",
        "  else:\n",
        "      model.turing_test()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're here??????\n",
            "Fuck me\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:308: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  '`tf.layers.batch_normalization` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:1294: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "  warnings.warn('`tf.layers.conv2d_transpose` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<__main__.Cifar10Model object at 0x7fb4acde1810>\n",
            "\n",
            "------------ Options -------------\n",
            "acc_thresh: 2.0\n",
            "augment: True\n",
            "batch_size: 60\n",
            "beta1: 0.0\n",
            "checkpoints_path: ./checkpoints\n",
            "color_space: lab\n",
            "dataset: CIFAR10_DATASET\n",
            "dataset_path: ./dataset/cifar10\n",
            "gpu_ids: 0\n",
            "l1_weight: 100.0\n",
            "label_smoothing: 1\n",
            "log: True\n",
            "log_interval: 10\n",
            "lr: 0.0003\n",
            "lr_decay: True\n",
            "lr_decay_rate: 0.1\n",
            "lr_decay_steps: 10000.0\n",
            "mode: 0\n",
            "name: MORTY\n",
            "sample: True\n",
            "sample_interval: 1000\n",
            "sample_size: 8\n",
            "save: True\n",
            "save_interval: 1000\n",
            "seed: 100\n",
            "test_input: \n",
            "test_output: \n",
            "training: True\n",
            "turing_test_delay: 0\n",
            "turing_test_size: 100\n",
            "validate: False\n",
            "validate_interval: 0\n",
            "visualize: True\n",
            "visualize_window: 100\n",
            "-------------- End ----------------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-b42d905a0da9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------- End ----------------\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-33bc5bc211e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-66d3821c5e20>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-66d3821c5e20>\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-75af148ee899>\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/data_batch_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mb'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4ad4226acea7>\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/cifar10/data_batch_1'"
          ]
        }
      ]
    }
  ]
}