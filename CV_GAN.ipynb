{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V9nHcs8503-k",
        "G7AjDhlq1YwV",
        "9EEgGNvIJ7hh",
        "I7RzZHDXTV8e",
        "r6C-SGESYa0j"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AronPerez/CS4933_Project/blob/corey/CV_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYWG4t9bDsJb"
      },
      "source": [
        "# Initial "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaCzvQgnxV3Z"
      },
      "source": [
        "## Aarons workspace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7scMenreKH1",
        "outputId": "ee1d98c7-f313-4200-cdc0-30b5b39ef257"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugjlyN850yz5"
      },
      "source": [
        "### Configs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY6QQAlxLXTj",
        "outputId": "76d3329e-5277-4203-da62-e5d5cc61b6a4"
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GP73R4ExU9F"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import pickle\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from scipy.misc import imread\n",
        "from abc import abstractmethod\n",
        "from __future__ import print_function\n",
        "from torchsummary import summary\n",
        "import torch\n",
        "import platform"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F2PRK-h8quW",
        "outputId": "dc7ac7c5-7b24-4b3d-e158-2b1f988a4943"
      },
      "source": [
        "# Prompt for input\n",
        "name = input(\"Select a model name \")\n",
        "while True:\n",
        "  dataset = input(\"Select a dataset, either places365_dataset or cifar10_dataset \")\n",
        "  if \"PLACES365\" in dataset.upper():\n",
        "    dataset = 'PLACE365_DATASET'\n",
        "    dataset_path = './dataset/places365'\n",
        "    break\n",
        "  elif 'CIFAR10' in dataset.upper():\n",
        "    dataset = 'CIFAR10_DATASET'\n",
        "    dataset_path = '/content/drive/MyDrive/CV/cifar10'\n",
        "    break\n",
        "  else:\n",
        "    print(\"Invalid dataset\")\n",
        "  \n",
        "batch_size = int(input(\"Please select a batch size \"))\n",
        "\n",
        "options = {\n",
        "    \"seed\": 100,\n",
        "    \"beta1\": 0.0,\n",
        "    \"name\": name.upper(),\n",
        "    \"mode\": 0,\n",
        "    \"dataset\": dataset,\n",
        "    \"dataset_path\": dataset_path,\n",
        "    \"checkpoints_path\": '/content/drive/MyDrive/CV/checkpoints',\n",
        "    \"color_space\": 'lab',\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": 10,\n",
        "    \"l1_weight\": 100.0,\n",
        "    \"lr\": 3e-4,\n",
        "    \"lr_decay\": True,\n",
        "    \"lr_decay_rate\": 0.1,\n",
        "    \"lr_decay_steps\": 1e4,\n",
        "    \"augment\": True,\n",
        "    \"acc_thresh\": 2.0,\n",
        "    \"gpu_ids\": 0,\n",
        "    \"save\": True,\n",
        "    \"save_interval\": 1000,\n",
        "    \"sample\": True,\n",
        "    \"sample_size\": 8,\n",
        "    \"sample_interval\": 1000,\n",
        "    \"validate\": True,\n",
        "    \"validate_interval\": 10000,\n",
        "    \"log\": True,\n",
        "    \"log_interval\": 834,\n",
        "    \"visualize\": True,\n",
        "    \"visualize_window\": 100,\n",
        "    \"test_input\": '',\n",
        "    \"test_output\": '',\n",
        "    \"turing_test_size\": 100,\n",
        "    \"turing_test_delay\": 0,\n",
        "    \"label_smoothing\": 1,\n",
        "    \"training\": True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select a model name ETF\n",
            "Select a dataset, either places365_dataset or cifar10_dataset cifar10_dataset \n",
            "Please select a batch size 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJk5dwX4LJNg"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP4_iitzL57G"
      },
      "source": [
        "CIFAR10_DATASET = 'cifar10'\n",
        "PLACES365_DATASET = 'places365'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "munjCgoxLKzA"
      },
      "source": [
        "class BaseDataset():\n",
        "    def __init__(self, name, path, training=True, augment=True):\n",
        "        self.name = name\n",
        "        self.augment = augment and training\n",
        "        self.training = training\n",
        "        self.path = path\n",
        "        self._data = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __iter__(self):\n",
        "        total = len(self)\n",
        "        start = 0\n",
        "\n",
        "        while start < total:\n",
        "            item = self[start]\n",
        "            start += 1\n",
        "            yield item\n",
        "        print(\"You're over here\")\n",
        "        raise StopIteration\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        val = self.data[index]\n",
        "        try:\n",
        "            img = imread(val) if isinstance(val, str) else val\n",
        "\n",
        "            # grayscale images\n",
        "            if np.sum(img[:,:,0] - img[:,:,1]) == 0 and np.sum(img[:,:,0] - img[:,:,2]) == 0:\n",
        "                return None\n",
        "\n",
        "            if self.augment and np.random.binomial(1, 0.5) == 1:\n",
        "                img = img[:, ::-1, :]\n",
        "\n",
        "        except:\n",
        "            img = None\n",
        "\n",
        "        return img\n",
        "\n",
        "    def generator(self, batch_size, recusrive=False):\n",
        "        start = 0\n",
        "        total = len(self)\n",
        "\n",
        "        while True:\n",
        "            while start < total:\n",
        "                end = np.min([start + batch_size, total])\n",
        "                items = []\n",
        "\n",
        "                for ix in range(start, end):\n",
        "                    item = self[ix]\n",
        "                    if item is not None:\n",
        "                        items.append(item)\n",
        "\n",
        "                start = end\n",
        "                yield items\n",
        "\n",
        "            if recusrive:\n",
        "                start = 0\n",
        "\n",
        "            else:\n",
        "                #print(\"Where am I?\")\n",
        "                return items\n",
        "\n",
        "    @property\n",
        "    def data(self):\n",
        "        if len(self._data) == 0:\n",
        "            self._data = self.load()\n",
        "            np.random.shuffle(self._data)\n",
        "\n",
        "        return self._data\n",
        "\n",
        "    @abstractmethod\n",
        "    def load(self):\n",
        "        return []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-4QgxFVL-In"
      },
      "source": [
        "class Cifar10Dataset(BaseDataset):\n",
        "    def __init__(self, path, training=True, augment=True):\n",
        "        super(Cifar10Dataset, self).__init__(CIFAR10_DATASET, path, training, augment)\n",
        "\n",
        "    def load(self):\n",
        "        data = []\n",
        "        if self.training:\n",
        "            for i in range(1, 6):\n",
        "                filename = '{}/data_batch_{}'.format(self.path, i)\n",
        "                batch_data = unpickle(filename)\n",
        "                if len(data) > 0:\n",
        "                    data = np.vstack((data, batch_data[b'data']))\n",
        "                else:\n",
        "                    data = batch_data[b'data']\n",
        "\n",
        "        else:\n",
        "            filename = '{}/test_batch'.format(self.path)\n",
        "            batch_data = unpickle(filename)\n",
        "            data = batch_data[b'data']\n",
        "\n",
        "        w = 32\n",
        "        h = 32\n",
        "        s = w * h\n",
        "        data = np.array(data)\n",
        "        data = np.dstack((data[:, :s], data[:, s:2 * s], data[:, 2 * s:]))\n",
        "        data = data.reshape((-1, w, h, 3))\n",
        "        return data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9nHcs8503-k"
      },
      "source": [
        "### Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcsc9ogM0HWy"
      },
      "source": [
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise ('Boolean value expected.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGA96OFazXZO"
      },
      "source": [
        "def parse(input):\n",
        "  opt = input\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu_ids\n",
        "  opt.color_space = opt.color_space.upper()\n",
        "  opt.training = opt.mode == 1\n",
        "\n",
        "  if opt.seed == 0:\n",
        "    opt.seed = random.randint(0, 2**31 - 1)\n",
        "\n",
        "  if opt.dataset_path == './dataset':\n",
        "    opt.dataset_path += ('/' + opt.dataset)\n",
        "\n",
        "  if opt.checkpoints_path == './checkpoints':\n",
        "    opt.checkpoints_path += ('/' + opt.dataset)\n",
        "\n",
        "    return opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7AjDhlq1YwV"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9F-MP9bJe5v"
      },
      "source": [
        "def stitch_images(grayscale, original, pred):\n",
        "    gap = 5\n",
        "    width, height = original[0][:, :, 0].shape\n",
        "    img_per_row = 2 if width > 200 else 4\n",
        "    img = Image.new('RGB', (width * img_per_row * 3 + gap * (img_per_row - 1), height * int(len(original) / img_per_row)))\n",
        "\n",
        "    grayscale = np.array(grayscale).squeeze()\n",
        "    original = np.array(original)\n",
        "    pred = np.array(pred)\n",
        "\n",
        "    for ix in range(len(original)):\n",
        "        xoffset = int(ix % img_per_row) * width * 3 + int(ix % img_per_row) * gap\n",
        "        yoffset = int(ix / img_per_row) * height\n",
        "        im1 = Image.fromarray(grayscale[ix])\n",
        "        im2 = Image.fromarray(original[ix])\n",
        "        im3 = Image.fromarray((pred[ix] * 255).astype(np.uint8))\n",
        "        img.paste(im1, (xoffset, yoffset))\n",
        "        img.paste(im2, (xoffset + width, yoffset))\n",
        "        img.paste(im3, (xoffset + width + width, yoffset))\n",
        "\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEE0LX0PJfnW"
      },
      "source": [
        "def create_dir(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "    return dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlLFjIcBJfg0"
      },
      "source": [
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_RoZnlEJfZK"
      },
      "source": [
        "def moving_average(data, window_width):\n",
        "    cumsum_vec = np.cumsum(np.insert(data, 0, 0))\n",
        "    ma_vec = (cumsum_vec[window_width:] - cumsum_vec[:-window_width]) / window_width\n",
        "    return ma_vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLckq20lJfQG"
      },
      "source": [
        "def imshow(img, title=''):\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.set_window_title(title)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation='none')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTAqlwtdJsTy"
      },
      "source": [
        "def imsave(img, path):\n",
        "    im = Image.fromarray(np.array(img).astype(np.uint8).squeeze())\n",
        "    im.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39WEh-A7JsiN"
      },
      "source": [
        "def turing_test(real_img, fake_img, delay=0):\n",
        "    height, width, _ = real_img.shape\n",
        "    imgs = np.array([real_img, (fake_img * 255).astype(np.uint8)])\n",
        "    real_index = np.random.binomial(1, 0.5)\n",
        "    fake_index = (real_index + 1) % 2\n",
        "\n",
        "    img = Image.new('RGB', (2 + width * 2, height))\n",
        "    img.paste(Image.fromarray(imgs[real_index]), (0, 0))\n",
        "    img.paste(Image.fromarray(imgs[fake_index]), (2 + width, 0))\n",
        "\n",
        "    img.success = 0\n",
        "\n",
        "    def onclick(event):\n",
        "        if event.xdata is not None:\n",
        "            if event.x < width and real_index == 0:\n",
        "                img.success = 1\n",
        "\n",
        "            elif event.x > width and real_index == 1:\n",
        "                img.success = 1\n",
        "\n",
        "        plt.gcf().canvas.stop_event_loop()\n",
        "\n",
        "    plt.ion()\n",
        "    plt.gcf().canvas.mpl_connect('button_press_event', onclick)\n",
        "    plt.title('click on the real image')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation='none')\n",
        "    plt.show()\n",
        "    plt.draw()\n",
        "    plt.gcf().canvas.start_event_loop(delay)\n",
        "\n",
        "    return img.success"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90FAEkHoJsyl"
      },
      "source": [
        "def visualize(train_log_file, test_log_file, window_width, title=''):\n",
        "    train_data = np.loadtxt(train_log_file)\n",
        "    test_data = np.loadtxt(test_log_file)\n",
        "\n",
        "    if len(train_data.shape) < 2:\n",
        "        return\n",
        "\n",
        "    if len(train_data) < window_width:\n",
        "        window_width = len(train_data) - 1\n",
        "\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.set_window_title(title)\n",
        "\n",
        "    plt.ion()\n",
        "    plt.subplot('121')\n",
        "    plt.cla()\n",
        "    if len(train_data) > 1:\n",
        "        plt.plot(moving_average(train_data[:, 8], window_width))\n",
        "    plt.title('train')\n",
        "\n",
        "    plt.subplot('122')\n",
        "    plt.cla()\n",
        "    if len(test_data) >= 1:\n",
        "        plt.plot(moving_average(test_data[:, 8], window_width))\n",
        "    plt.title('test')\n",
        "\n",
        "    plt.show()\n",
        "    plt.draw()\n",
        "    plt.pause(.01)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EEgGNvIJ7hh"
      },
      "source": [
        "### Ops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNh-LQlFKDmi"
      },
      "source": [
        "COLORSPACE_RGB = 'RGB'\n",
        "COLORSPACE_LAB = 'LAB'\n",
        "#tf.nn.softmax_cross_entropy_with_logits_v2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDFVi6SYKAkM"
      },
      "source": [
        "def conv2d(inputs, filters, name, kernel_size=4, strides=2, bnorm=True, activation=None, seed=None):\n",
        "    \"\"\"\n",
        "    Creates a conv2D block\n",
        "    \"\"\"\n",
        "    initializer=tf.variance_scaling_initializer(seed=seed)\n",
        "    res = tf.layers.conv2d(\n",
        "        name=name,\n",
        "        inputs=inputs,\n",
        "        filters=filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=initializer)\n",
        "\n",
        "    if bnorm:\n",
        "        res = tf.layers.batch_normalization(inputs=res, name='bn_' + name, training=True)\n",
        "\n",
        "    # activation after batch-norm\n",
        "    if activation is not None:\n",
        "        res = activation(res)\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5d84dahKAeM"
      },
      "source": [
        "def conv2d_transpose(inputs, filters, name, kernel_size=4, strides=2, bnorm=True, activation=None, seed=None):\n",
        "    \"\"\"\n",
        "    Creates a conv2D-transpose block\n",
        "    \"\"\"\n",
        "    initializer=tf.variance_scaling_initializer(seed=seed)\n",
        "    res = tf.layers.conv2d_transpose(\n",
        "        name=name,\n",
        "        inputs=inputs,\n",
        "        filters=filters,\n",
        "        kernel_size=kernel_size,\n",
        "        strides=strides,\n",
        "        padding=\"same\",\n",
        "        kernel_initializer=initializer)\n",
        "\n",
        "    if bnorm:\n",
        "        res = tf.layers.batch_normalization(inputs=res, name='bn_' + name, training=True)\n",
        "\n",
        "    # activation after batch-norm\n",
        "    if activation is not None:\n",
        "        res = activation(res)\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ1K6xBEKAYw"
      },
      "source": [
        "def pixelwise_accuracy(img_real, img_fake, colorspace, thresh):\n",
        "    \"\"\"\n",
        "    Measures the accuracy of the colorization process by comparing pixels\n",
        "    \"\"\"\n",
        "    img_real = postprocess(img_real, colorspace, COLORSPACE_LAB)\n",
        "    img_fake = postprocess(img_fake, colorspace, COLORSPACE_LAB)\n",
        "\n",
        "    diffL = tf.abs(tf.round(img_real[..., 0]) - tf.round(img_fake[..., 0]))\n",
        "    diffA = tf.abs(tf.round(img_real[..., 1]) - tf.round(img_fake[..., 1]))\n",
        "    diffB = tf.abs(tf.round(img_real[..., 2]) - tf.round(img_fake[..., 2]))\n",
        "\n",
        "    # within %thresh of the original\n",
        "    predL = tf.cast(tf.less_equal(diffL, 1 * thresh), tf.float64)        # L: [0, 100]\n",
        "    predA = tf.cast(tf.less_equal(diffA, 2.2 * thresh), tf.float64)      # A: [-110, 110]\n",
        "    predB = tf.cast(tf.less_equal(diffB, 2.2 * thresh), tf.float64)      # B: [-110, 110]\n",
        "\n",
        "    # all three channels are within the threshold\n",
        "    pred = predL * predA * predB\n",
        "\n",
        "    return tf.reduce_mean(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n-SkClBKASx"
      },
      "source": [
        "def preprocess(img, colorspace_in, colorspace_out):\n",
        "    if colorspace_out.upper() == COLORSPACE_RGB:\n",
        "        if colorspace_in == COLORSPACE_LAB:\n",
        "            img = lab_to_rgb(img)\n",
        "\n",
        "        # [0, 1] => [-1, 1]\n",
        "        img = (img / 255.0) * 2 - 1\n",
        "\n",
        "    elif colorspace_out.upper() == COLORSPACE_LAB:\n",
        "        if colorspace_in == COLORSPACE_RGB:\n",
        "            img = rgb_to_lab(img / 255.0)\n",
        "\n",
        "        L_chan, a_chan, b_chan = tf.unstack(img, axis=3)\n",
        "\n",
        "        # L: [0, 100] => [-1, 1]\n",
        "        # A, B: [-110, 110] => [-1, 1]\n",
        "        img = tf.stack([L_chan / 50 - 1, a_chan / 110, b_chan / 110], axis=3)\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZcMVbpNKANL"
      },
      "source": [
        "def postprocess(img, colorspace_in, colorspace_out):\n",
        "    if colorspace_in.upper() == COLORSPACE_RGB:\n",
        "        # [-1, 1] => [0, 1]\n",
        "        img = (img + 1) / 2\n",
        "\n",
        "        if colorspace_out == COLORSPACE_LAB:\n",
        "            img = rgb_to_lab(img)\n",
        "\n",
        "    elif colorspace_in.upper() == COLORSPACE_LAB:\n",
        "        L_chan, a_chan, b_chan = tf.unstack(img, axis=3)\n",
        "\n",
        "        # L: [-1, 1] => [0, 100]\n",
        "        # A, B: [-1, 1] => [-110, 110]\n",
        "        img = tf.stack([(L_chan + 1) / 2 * 100, a_chan * 110, b_chan * 110], axis=3)\n",
        "\n",
        "        if colorspace_out == COLORSPACE_RGB:\n",
        "            img = lab_to_rgb(img)\n",
        "\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n537DjJYKAFc"
      },
      "source": [
        "def rgb_to_lab(srgb):\n",
        "    # based on https://github.com/torch/image/blob/9f65c30167b2048ecbe8b7befdc6b2d6d12baee9/generic/image.c\n",
        "    with tf.name_scope(\"rgb_to_lab\"):\n",
        "        srgb_pixels = tf.reshape(srgb, [-1, 3])\n",
        "\n",
        "        with tf.name_scope(\"srgb_to_xyz\"):\n",
        "            linear_mask = tf.cast(srgb_pixels <= 0.04045, dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(srgb_pixels > 0.04045, dtype=tf.float32)\n",
        "            rgb_pixels = (srgb_pixels / 12.92 * linear_mask) + (((srgb_pixels + 0.055) / 1.055) ** 2.4) * exponential_mask\n",
        "            rgb_to_xyz = tf.constant([\n",
        "                #    X        Y          Z\n",
        "                [0.412453, 0.212671, 0.019334],  # R\n",
        "                [0.357580, 0.715160, 0.119193],  # G\n",
        "                [0.180423, 0.072169, 0.950227],  # B\n",
        "            ])\n",
        "            xyz_pixels = tf.matmul(rgb_pixels, rgb_to_xyz)\n",
        "\n",
        "        # https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
        "        with tf.name_scope(\"xyz_to_cielab\"):\n",
        "\n",
        "            # normalize for D65 white point\n",
        "            xyz_normalized_pixels = tf.multiply(xyz_pixels, [1 / 0.950456, 1.0, 1 / 1.088754])\n",
        "\n",
        "            epsilon = 6 / 29\n",
        "            linear_mask = tf.cast(xyz_normalized_pixels <= (epsilon**3), dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(xyz_normalized_pixels > (epsilon**3), dtype=tf.float32)\n",
        "            fxfyfz_pixels = (xyz_normalized_pixels / (3 * epsilon**2) + 4 / 29) * linear_mask + (xyz_normalized_pixels ** (1 / 3)) * exponential_mask\n",
        "\n",
        "            # convert to lab\n",
        "            fxfyfz_to_lab = tf.constant([\n",
        "                #  l       a       b\n",
        "                [0.0, 500.0, 0.0],  # fx\n",
        "                [116.0, -500.0, 200.0],  # fy\n",
        "                [0.0, 0.0, -200.0],  # fz\n",
        "            ])\n",
        "            lab_pixels = tf.matmul(fxfyfz_pixels, fxfyfz_to_lab) + tf.constant([-16.0, 0.0, 0.0])\n",
        "\n",
        "        return tf.reshape(lab_pixels, tf.shape(srgb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4_LOFJUJ_3d"
      },
      "source": [
        "def lab_to_rgb(lab):\n",
        "    with tf.name_scope(\"lab_to_rgb\"):\n",
        "        lab_pixels = tf.reshape(lab, [-1, 3])\n",
        "\n",
        "        # https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions\n",
        "        with tf.name_scope(\"cielab_to_xyz\"):\n",
        "            # convert to fxfyfz\n",
        "            lab_to_fxfyfz = tf.constant([\n",
        "                #   fx      fy        fz\n",
        "                [1 / 116.0, 1 / 116.0, 1 / 116.0],  # l\n",
        "                [1 / 500.0, 0.0, 0.0],  # a\n",
        "                [0.0, 0.0, -1 / 200.0],  # b\n",
        "            ])\n",
        "            fxfyfz_pixels = tf.matmul(lab_pixels + tf.constant([16.0, 0.0, 0.0]), lab_to_fxfyfz)\n",
        "\n",
        "            # convert to xyz\n",
        "            epsilon = 6 / 29\n",
        "            linear_mask = tf.cast(fxfyfz_pixels <= epsilon, dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(fxfyfz_pixels > epsilon, dtype=tf.float32)\n",
        "            xyz_pixels = (3 * epsilon**2 * (fxfyfz_pixels - 4 / 29)) * linear_mask + (fxfyfz_pixels ** 3) * exponential_mask\n",
        "\n",
        "            # denormalize for D65 white point\n",
        "            xyz_pixels = tf.multiply(xyz_pixels, [0.950456, 1.0, 1.088754])\n",
        "\n",
        "        with tf.name_scope(\"xyz_to_srgb\"):\n",
        "            xyz_to_rgb = tf.constant([\n",
        "                #     r           g          b\n",
        "                [3.2404542, -0.9692660, 0.0556434],  # x\n",
        "                [-1.5371385, 1.8760108, -0.2040259],  # y\n",
        "                [-0.4985314, 0.0415560, 1.0572252],  # z\n",
        "            ])\n",
        "            rgb_pixels = tf.matmul(xyz_pixels, xyz_to_rgb)\n",
        "            # avoid a slightly negative number messing up the conversion\n",
        "            rgb_pixels = tf.clip_by_value(rgb_pixels, 0.0, 1.0)\n",
        "            linear_mask = tf.cast(rgb_pixels <= 0.0031308, dtype=tf.float32)\n",
        "            exponential_mask = tf.cast(rgb_pixels > 0.0031308, dtype=tf.float32)\n",
        "            srgb_pixels = (rgb_pixels * 12.92 * linear_mask) + ((rgb_pixels ** (1 / 2.4) * 1.055) - 0.055) * exponential_mask\n",
        "\n",
        "        return tf.reshape(srgb_pixels, tf.shape(lab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHwXO1oCTiiM"
      },
      "source": [
        "class Progbar(object):\n",
        "    \"\"\"Displays a progress bar.\n",
        "    Arguments:\n",
        "        target: Total number of steps expected, None if unknown.\n",
        "        width: Progress bar width on screen.\n",
        "        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n",
        "        stateful_metrics: Iterable of string names of metrics that\n",
        "            should *not* be averaged over time. Metrics in this list\n",
        "            will be displayed as-is. All others will be averaged\n",
        "            by the progbar before display.\n",
        "        interval: Minimum visual progress update interval (in seconds).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target, width=25, verbose=1, interval=0.05,\n",
        "                 stateful_metrics=None):\n",
        "        self.target = target\n",
        "        self.width = width\n",
        "        self.verbose = verbose\n",
        "        self.interval = interval\n",
        "        if stateful_metrics:\n",
        "            self.stateful_metrics = set(stateful_metrics)\n",
        "        else:\n",
        "            self.stateful_metrics = set()\n",
        "\n",
        "        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n",
        "                                  sys.stdout.isatty()) or\n",
        "                                 'ipykernel' in sys.modules or\n",
        "                                 'posix' in sys.modules)\n",
        "        self._total_width = 0\n",
        "        self._seen_so_far = 0\n",
        "        # We use a dict + list to avoid garbage collection\n",
        "        # issues found in OrderedDict\n",
        "        self._values = {}\n",
        "        self._values_order = []\n",
        "        self._start = time.time()\n",
        "        self._last_update = 0\n",
        "\n",
        "    def update(self, current, values=None):\n",
        "        \"\"\"Updates the progress bar.\n",
        "        Arguments:\n",
        "            current: Index of current step.\n",
        "            values: List of tuples:\n",
        "                `(name, value_for_last_step)`.\n",
        "                If `name` is in `stateful_metrics`,\n",
        "                `value_for_last_step` will be displayed as-is.\n",
        "                Else, an average of the metric over time will be displayed.\n",
        "        \"\"\"\n",
        "        values = values or []\n",
        "        for k, v in values:\n",
        "            if k not in self._values_order:\n",
        "                self._values_order.append(k)\n",
        "            if k not in self.stateful_metrics:\n",
        "                if k not in self._values:\n",
        "                    self._values[k] = [v * (current - self._seen_so_far),\n",
        "                                       current - self._seen_so_far]\n",
        "                else:\n",
        "                    self._values[k][0] += v * (current - self._seen_so_far)\n",
        "                    self._values[k][1] += (current - self._seen_so_far)\n",
        "            else:\n",
        "                self._values[k] = v\n",
        "        self._seen_so_far = current\n",
        "\n",
        "        now = time.time()\n",
        "        info = ' - %.0fs' % (now - self._start)\n",
        "        if self.verbose == 1:\n",
        "            if (now - self._last_update < self.interval and\n",
        "                    self.target is not None and current < self.target):\n",
        "                return\n",
        "\n",
        "            prev_total_width = self._total_width\n",
        "            if self._dynamic_display:\n",
        "                sys.stdout.write('\\b' * prev_total_width)\n",
        "                sys.stdout.write('\\r')\n",
        "            else:\n",
        "                sys.stdout.write('\\n')\n",
        "\n",
        "            if self.target is not None:\n",
        "                numdigits = int(np.floor(np.log10(self.target))) + 1\n",
        "                barstr = '%%%dd/%d [' % (numdigits, self.target)\n",
        "                bar = barstr % current\n",
        "                prog = float(current) / self.target\n",
        "                prog_width = int(self.width * prog)\n",
        "                if prog_width > 0:\n",
        "                    bar += ('=' * (prog_width - 1))\n",
        "                    if current < self.target:\n",
        "                        bar += '>'\n",
        "                    else:\n",
        "                        bar += '='\n",
        "                bar += ('.' * (self.width - prog_width))\n",
        "                bar += ']'\n",
        "            else:\n",
        "                bar = '%7d/Unknown' % current\n",
        "\n",
        "            self._total_width = len(bar)\n",
        "            sys.stdout.write(bar)\n",
        "\n",
        "            if current:\n",
        "                time_per_unit = (now - self._start) / current\n",
        "            else:\n",
        "                time_per_unit = 0\n",
        "            if self.target is not None and current < self.target:\n",
        "                eta = time_per_unit * (self.target - current)\n",
        "                if eta > 3600:\n",
        "                    eta_format = '%d:%02d:%02d' % (eta // 3600,\n",
        "                                                   (eta % 3600) // 60,\n",
        "                                                   eta % 60)\n",
        "                elif eta > 60:\n",
        "                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n",
        "                else:\n",
        "                    eta_format = '%ds' % eta\n",
        "\n",
        "                info = ' - ETA: %s' % eta_format\n",
        "            else:\n",
        "                if time_per_unit >= 1:\n",
        "                    info += ' %.0fs/step' % time_per_unit\n",
        "                elif time_per_unit >= 1e-3:\n",
        "                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n",
        "                else:\n",
        "                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n",
        "\n",
        "            for k in self._values_order:\n",
        "                info += ' - %s:' % k\n",
        "                if isinstance(self._values[k], list):\n",
        "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
        "                    if abs(avg) > 1e-3:\n",
        "                        info += ' %.4f' % avg\n",
        "                    else:\n",
        "                        info += ' %.4e' % avg\n",
        "                else:\n",
        "                    info += ' %s' % self._values[k]\n",
        "\n",
        "            self._total_width += len(info)\n",
        "            if prev_total_width > self._total_width:\n",
        "                info += (' ' * (prev_total_width - self._total_width))\n",
        "\n",
        "            if self.target is not None and current >= self.target:\n",
        "                info += '\\n'\n",
        "\n",
        "            sys.stdout.write(info)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        elif self.verbose == 2:\n",
        "            if self.target is None or current >= self.target:\n",
        "                for k in self._values_order:\n",
        "                    info += ' - %s:' % k\n",
        "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
        "                    if avg > 1e-3:\n",
        "                        info += ' %.4f' % avg\n",
        "                    else:\n",
        "                        info += ' %.4e' % avg\n",
        "                info += '\\n'\n",
        "\n",
        "                sys.stdout.write(info)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        self._last_update = now\n",
        "\n",
        "    def add(self, n, values=None):\n",
        "        self.update(self._seen_so_far + n, values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7RzZHDXTV8e"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VjuibMyTa_T"
      },
      "source": [
        "class BaseModel:\n",
        "    def __init__(self, sess, options):\n",
        "        self.sess = sess\n",
        "        self.options = options\n",
        "        self.name = options[\"name\"]\n",
        "        self.samples_dir = os.path.join(options[\"checkpoints_path\"], 'samples')\n",
        "        self.test_log_file = os.path.join(options[\"checkpoints_path\"], 'log_test.dat')\n",
        "        self.train_log_file = os.path.join(options[\"checkpoints_path\"], 'log_train.dat')\n",
        "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "        self.dataset_train = self.create_dataset(True)\n",
        "        self.dataset_val = self.create_dataset(False)\n",
        "        self.sample_generator = self.dataset_val.generator(options[\"sample_size\"], True)\n",
        "        self.iteration = 0\n",
        "        self.epoch = 0\n",
        "        self.is_built = False\n",
        "\n",
        "    def train(self):\n",
        "        total = len(self.dataset_train)\n",
        "\n",
        "        for epoch in range(options[\"epochs\"]):\n",
        "            lr_rate = self.sess.run(self.learning_rate)\n",
        "\n",
        "            print('Training epoch: %d' % (epoch + 1) + \" - learning rate: \" + str(lr_rate))\n",
        "\n",
        "            self.epoch = epoch + 1\n",
        "            self.iteration = 0\n",
        "\n",
        "            generator = self.dataset_train.generator(options[\"batch_size\"])\n",
        "            progbar = Progbar(total, width=25, stateful_metrics=['epoch', 'iter', 'step'])\n",
        "    \n",
        "            for input_rgb in generator:\n",
        "                feed_dic = {self.input_rgb: input_rgb}\n",
        "\n",
        "                self.iteration = self.iteration + 1\n",
        "                self.sess.run([self.dis_train], feed_dict=feed_dic)\n",
        "                self.sess.run([self.gen_train, self.accuracy], feed_dict=feed_dic)\n",
        "                self.sess.run([self.gen_train, self.accuracy], feed_dict=feed_dic)\n",
        "\n",
        "                lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc, step = self.eval_outputs(feed_dic=feed_dic)\n",
        "\n",
        "                progbar.add(len(input_rgb), values=[\n",
        "                    (\"epoch\", epoch + 1),\n",
        "                    (\"iter\", self.iteration),\n",
        "                    (\"step\", step),\n",
        "                    (\"D loss\", lossD),\n",
        "                    (\"D fake\", lossD_fake),\n",
        "                    (\"D real\", lossD_real),\n",
        "                    (\"G loss\", lossG),\n",
        "                    (\"G L1\", lossG_l1),\n",
        "                    (\"G gan\", lossG_gan),\n",
        "                    (\"accuracy\", acc)\n",
        "                ])\n",
        "\n",
        "                # log model at checkpoints\n",
        "                if options[\"log\"] and step % options[\"log_interval\"] == 0:\n",
        "                    with open(self.train_log_file, 'a') as f:\n",
        "                        f.write('%d %d %f %f %f %f %f %f %f\\n' % (self.epoch, step, lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc))\n",
        "\n",
        "                    if options[\"visualize\"]:\n",
        "                        visualize(self.train_log_file, self.test_log_file, options[\"visualize_window\"], self.name)\n",
        "\n",
        "                # sample model at checkpoints\n",
        "                if options[\"sample\"] and step % options[\"sample_interval\"] == 0:\n",
        "                    self.sample(show=False)\n",
        "\n",
        "                # validate model at checkpoints\n",
        "                if options[\"validate\"] and options[\"validate_interval\"] > 0 and step % options[\"validate_interval\"] == 0:\n",
        "                    self.validate()\n",
        "\n",
        "                # save model at checkpoints\n",
        "                if options[\"save\"] and step % options[\"save_interval\"] == 0:\n",
        "                    self.save()\n",
        "\n",
        "            if options[\"validate\"]:\n",
        "                self.validate()\n",
        "\n",
        "    def validate(self):\n",
        "        print('\\n\\nValidating epoch: %d' % self.epoch)\n",
        "        total = len(self.dataset_val)\n",
        "        val_generator = self.dataset_val.generator(options[\"batch_size\"])\n",
        "        progbar = Progbar(total, width=25)\n",
        "\n",
        "        for input_rgb in val_generator:\n",
        "            feed_dic = {self.input_rgb: input_rgb}\n",
        "\n",
        "            self.sess.run([self.dis_loss, self.gen_loss, self.accuracy], feed_dict=feed_dic)\n",
        "\n",
        "            lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc, step = self.eval_outputs(feed_dic=feed_dic)\n",
        "\n",
        "            progbar.add(len(input_rgb), values=[\n",
        "                (\"D loss\", lossD),\n",
        "                (\"D fake\", lossD_fake),\n",
        "                (\"D real\", lossD_real),\n",
        "                (\"G loss\", lossG),\n",
        "                (\"G L1\", lossG_l1),\n",
        "                (\"G gan\", lossG_gan),\n",
        "                (\"accuracy\", acc)\n",
        "            ])\n",
        "            with open(self.test_log_file, 'a') as f:\n",
        "              f.write('%d %d %f %f %f %f %f %f %f\\n' % (self.epoch, step, lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc))\n",
        "\n",
        "        print('\\n')\n",
        "\n",
        "    def test(self):\n",
        "        print('\\nTesting...')\n",
        "        dataset = TestDataset(options[\"test_input\"] or (options[\"checkpoints_path\"] + '/test'))\n",
        "        outputs_path = create_dir(options[\"test_output\"] or (options[\"checkpoints_path\"] + '/output'))\n",
        "\n",
        "        for index in range(len(dataset)):\n",
        "            img_gray_path, img_gray = dataset[index]\n",
        "            name = os.path.basename(img_gray_path)\n",
        "            path = os.path.join(outputs_path, name)\n",
        "\n",
        "            feed_dic = {self.input_gray: img_gray[None, :, :, None]}\n",
        "            outputs = self.sess.run(self.sampler, feed_dict=feed_dic)\n",
        "            outputs = postprocess(tf.convert_to_tensor(outputs), colorspace_in=options[\"color_space\"], colorspace_out=COLORSPACE_RGB).eval() * 255\n",
        "            print(path)\n",
        "            imsave(outputs[0], path)\n",
        "\n",
        "    def sample(self, show=True):\n",
        "        input_rgb = next(self.sample_generator)\n",
        "        feed_dic = {self.input_rgb: input_rgb}\n",
        "\n",
        "        step, rate = self.sess.run([self.global_step, self.learning_rate])\n",
        "        fake_image, input_gray = self.sess.run([self.sampler, self.input_gray], feed_dict=feed_dic)\n",
        "        fake_image = postprocess(tf.convert_to_tensor(fake_image), colorspace_in=options[\"color_space\"], colorspace_out=COLORSPACE_RGB)\n",
        "        img = stitch_images(input_gray, input_rgb, fake_image.eval())\n",
        "\n",
        "        create_dir(self.samples_dir)\n",
        "        sample = options[\"dataset\"] + \"_\" + str(step).zfill(5) + \".png\"\n",
        "\n",
        "        if show:\n",
        "            imshow(np.array(img), self.name)\n",
        "        else:\n",
        "            print('\\nsaving sample ' + sample + ' - learning rate: ' + str(rate))\n",
        "            img.save(os.path.join(self.samples_dir, sample))\n",
        "\n",
        "    def turing_test(self):\n",
        "        batch_size = options[\"batch_size\"]\n",
        "        gen = self.dataset_val.generator(batch_size, True)\n",
        "        count = 0\n",
        "        score = 0\n",
        "        size = options[\"turing_test_size\"]\n",
        "\n",
        "        while count < size:\n",
        "            input_rgb = next(gen)\n",
        "            feed_dic = {self.input_rgb: input_rgb}\n",
        "            fake_image = self.sess.run(self.sampler, feed_dict=feed_dic)\n",
        "            fake_image = postprocess(tf.convert_to_tensor(fake_image), colorspace_in=options[\"color_space\"], colorspace_out=COLORSPACE_RGB)\n",
        "\n",
        "            for i in range(np.min([batch_size, size - count])):\n",
        "                res = turing_test(input_rgb[i], fake_image.eval()[i], options[\"turing_test_delay\"])\n",
        "                count += 1\n",
        "                score += res\n",
        "                print('success: %d - fail: %d - rate: %f' % (score, count - score, (count - score) / count))\n",
        "\n",
        "    def build(self):\n",
        "        if self.is_built:\n",
        "            return\n",
        "        print(\"We're here??????\")\n",
        "        self.is_built = True\n",
        "\n",
        "        gen_factory = self.create_generator()\n",
        "        dis_factory = self.create_discriminator()\n",
        "        smoothing = 0.9 if options[\"label_smoothing\"] else 1\n",
        "        seed = options[\"seed\"]\n",
        "        kernel = 4\n",
        "\n",
        "        # model input placeholder: RGB imaege\n",
        "        self.input_rgb = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='input_rgb')\n",
        "        print(\"Fuck me\")\n",
        "        # model input after preprocessing: LAB image\n",
        "        self.input_color = preprocess(self.input_rgb, colorspace_in=COLORSPACE_RGB, colorspace_out=options[\"color_space\"])\n",
        "\n",
        "        # test mode: model input is a graycale placeholder\n",
        "        if options[\"mode\"] == 1:\n",
        "            self.input_gray = tf.placeholder(tf.float32, shape=(None, None, None, 1), name='input_gray')\n",
        "\n",
        "        # train/turing-test we extract grayscale image from color image\n",
        "        else:\n",
        "            self.input_gray = tf.image.rgb_to_grayscale(self.input_rgb)\n",
        "\n",
        "        gen = gen_factory.create(self.input_gray, kernel, seed)\n",
        "        dis_real = dis_factory.create(tf.concat([self.input_gray, self.input_color], 3), kernel, seed)\n",
        "        dis_fake = dis_factory.create(tf.concat([self.input_gray, gen], 3), kernel, seed, reuse_variables=True)\n",
        "\n",
        "        gen_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.ones_like(dis_fake))\n",
        "        dis_real_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_real, labels=tf.ones_like(dis_real) * smoothing)\n",
        "        dis_fake_ce = tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake, labels=tf.zeros_like(dis_fake))\n",
        "\n",
        "        self.dis_loss_real = tf.reduce_mean(dis_real_ce)\n",
        "        self.dis_loss_fake = tf.reduce_mean(dis_fake_ce)\n",
        "        self.dis_loss = tf.reduce_mean(dis_real_ce + dis_fake_ce)\n",
        "\n",
        "        self.gen_loss_gan = tf.reduce_mean(gen_ce)\n",
        "        self.gen_loss_l1 = tf.reduce_mean(tf.abs(self.input_color - gen)) * options[\"l1_weight\"]\n",
        "        self.gen_loss = self.gen_loss_gan + self.gen_loss_l1\n",
        "\n",
        "        self.sampler = tf.identity(gen_factory.create(self.input_gray, kernel, seed, reuse_variables=True), name='output')\n",
        "        self.accuracy = pixelwise_accuracy(self.input_color, gen, options[\"color_space\"], options[\"acc_thresh\"])\n",
        "        self.learning_rate = tf.constant(options[\"lr\"])\n",
        "\n",
        "        # learning rate decay\n",
        "        if options[\"lr_decay\"] and options[\"lr_decay\"] > 0:\n",
        "            self.learning_rate = tf.maximum(1e-6, tf.train.exponential_decay(\n",
        "                learning_rate=options[\"lr\"],\n",
        "                global_step=self.global_step,\n",
        "                decay_steps=options[\"lr_decay_steps\"],\n",
        "                decay_rate=options[\"lr_decay_rate\"]))\n",
        "\n",
        "        # generator optimizaer\n",
        "        self.gen_train = tf.train.AdamOptimizer(\n",
        "            learning_rate=self.learning_rate,\n",
        "            beta1=options[\"beta1\"]\n",
        "        ).minimize(self.gen_loss, var_list=gen_factory.var_list)\n",
        "\n",
        "        # discriminator optimizaer\n",
        "        self.dis_train = tf.train.AdamOptimizer(\n",
        "            learning_rate=self.learning_rate / 10,\n",
        "            beta1=options[\"beta1\"]\n",
        "        ).minimize(self.dis_loss, var_list=dis_factory.var_list, global_step=self.global_step)\n",
        "\n",
        "        self.saver = tf.train.Saver()\n",
        "\n",
        "    def load(self):\n",
        "        ckpt = tf.train.get_checkpoint_state(options[\"checkpoints_path\"])\n",
        "        if ckpt is not None:\n",
        "            print('loading model...\\n')\n",
        "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "            self.saver.restore(self.sess, os.path.join(options[\"checkpoints_path\"], ckpt_name))\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def save(self):\n",
        "        print('saving model...\\n')\n",
        "        self.saver.save(self.sess, os.path.join(options[\"checkpoints_path\"], 'CGAN_' + options[\"dataset\"]), write_meta_graph=False)\n",
        "\n",
        "    def eval_outputs(self, feed_dic):\n",
        "        '''\n",
        "        evaluates the loss and accuracy\n",
        "        returns (D loss, D_fake loss, D_real loss, G loss, G_L1 loss, G_gan loss, accuracy, step)\n",
        "        '''\n",
        "        lossD_fake = self.dis_loss_fake.eval(feed_dict=feed_dic)\n",
        "        lossD_real = self.dis_loss_real.eval(feed_dict=feed_dic)\n",
        "        lossD = self.dis_loss.eval(feed_dict=feed_dic)\n",
        "\n",
        "        lossG_l1 = self.gen_loss_l1.eval(feed_dict=feed_dic)\n",
        "        lossG_gan = self.gen_loss_gan.eval(feed_dict=feed_dic)\n",
        "        lossG = lossG_l1 + lossG_gan\n",
        "\n",
        "        acc = self.accuracy.eval(feed_dict=feed_dic)\n",
        "        step = self.sess.run(self.global_step)\n",
        "\n",
        "        return lossD, lossD_fake, lossD_real, lossG, lossG_l1, lossG_gan, acc, step\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_generator(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_discriminator(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    @abstractmethod\n",
        "    def create_dataset(self, training):\n",
        "        raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZvxkLLZVEEK"
      },
      "source": [
        "class Cifar10Model(BaseModel):\n",
        "    def __init__(self, sess, options):\n",
        "        super(Cifar10Model, self).__init__(sess, options)\n",
        "\n",
        "    def create_generator(self):\n",
        "        kernels_gen_encoder = [\n",
        "            (64, 1, 0),     # [batch, 32, 32, ch] => [batch, 32, 32, 64]\n",
        "            (128, 2, 0),    # [batch, 32, 32, 64] => [batch, 16, 16, 128]\n",
        "            (256, 2, 0),    # [batch, 16, 16, 128] => [batch, 8, 8, 256]\n",
        "            (512, 2, 0),    # [batch, 8, 8, 256] => [batch, 4, 4, 512]\n",
        "            (512, 2, 0),    # [batch, 4, 4, 512] => [batch, 2, 2, 512]\n",
        "        ]\n",
        "\n",
        "        kernels_gen_decoder = [\n",
        "            (512, 2, 0.5),  # [batch, 2, 2, 512] => [batch, 4, 4, 512]\n",
        "            (256, 2, 0.5),  # [batch, 4, 4, 512] => [batch, 8, 8, 256]\n",
        "            (128, 2, 0),    # [batch, 8, 8, 256] => [batch, 16, 16, 128]\n",
        "            (64, 2, 0),     # [batch, 16, 16, 128] => [batch, 32, 32, 64]\n",
        "        ]\n",
        "\n",
        "        return Generator('gen', kernels_gen_encoder, kernels_gen_decoder, training=options[\"training\"])\n",
        "\n",
        "    def create_discriminator(self):\n",
        "        kernels_dis = [\n",
        "            (64, 2, 0),     # [batch, 32, 32, ch] => [batch, 16, 16, 64]\n",
        "            (128, 2, 0),    # [batch, 16, 16, 64] => [batch, 8, 8, 128]\n",
        "            (256, 2, 0),    # [batch, 8, 8, 128] => [batch, 4, 4, 256]\n",
        "            (512, 1, 0),    # [batch, 4, 4, 256] => [batch, 4, 4, 512]\n",
        "        ]\n",
        "\n",
        "        return Discriminator('dis', kernels_dis, training=options[\"training\"])\n",
        "\n",
        "    def create_dataset(self, training=True):\n",
        "        return Cifar10Dataset(\n",
        "            path=self.options[\"dataset_path\"],\n",
        "            training=training,\n",
        "            augment=self.options[\"augment\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6C-SGESYa0j"
      },
      "source": [
        "### Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxePEOwkYqCc"
      },
      "source": [
        "class Discriminator(object):\n",
        "    def __init__(self, name, kernels, training=True):\n",
        "        self.name = name\n",
        "        self.kernels = kernels\n",
        "        self.training = training\n",
        "        self.var_list = []\n",
        "\n",
        "    def create(self, inputs, kernel_size=None, seed=None, reuse_variables=None):\n",
        "        output = inputs\n",
        "        with tf.variable_scope(self.name, reuse=reuse_variables):\n",
        "            for index, kernel in enumerate(self.kernels):\n",
        "\n",
        "                # not use batch-norm in the first layer\n",
        "                bnorm = False if index == 0 else True\n",
        "                name = 'conv' + str(index)\n",
        "                output = conv2d(\n",
        "                    inputs=output,\n",
        "                    name=name,\n",
        "                    kernel_size=kernel_size,\n",
        "                    filters=kernel[0],\n",
        "                    strides=kernel[1],\n",
        "                    bnorm=bnorm,\n",
        "                    activation=tf.nn.leaky_relu,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                if kernel[2] > 0:\n",
        "                    keep_prob = 1.0 - kernel[2] if self.training else 1.0\n",
        "                    output = tf.nn.dropout(output, keep_prob=keep_prob, name='dropout_' + name, seed=seed)\n",
        "\n",
        "            output = conv2d(\n",
        "                inputs=output,\n",
        "                name='conv_last',\n",
        "                filters=1,\n",
        "                kernel_size=4,                  # last layer kernel size = 4\n",
        "                strides=1,                      # last layer stride = 1\n",
        "                bnorm=False,                    # do not use batch-norm for the last layer\n",
        "                seed=seed\n",
        "            )\n",
        "\n",
        "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
        "\n",
        "            return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbA0lbXAYsG-"
      },
      "source": [
        "class Generator(object):\n",
        "    def __init__(self, name, encoder_kernels, decoder_kernels, output_channels=3, training=True):\n",
        "        self.name = name\n",
        "        self.encoder_kernels = encoder_kernels\n",
        "        self.decoder_kernels = decoder_kernels\n",
        "        self.output_channels = output_channels\n",
        "        self.training = training\n",
        "        self.var_list = []\n",
        "\n",
        "    def create(self, inputs, kernel_size=None, seed=None, reuse_variables=None):\n",
        "        output = inputs\n",
        "\n",
        "        with tf.variable_scope(self.name, reuse=reuse_variables):\n",
        "\n",
        "            layers = []\n",
        "\n",
        "            # encoder branch\n",
        "            for index, kernel in enumerate(self.encoder_kernels):\n",
        "\n",
        "                name = 'conv' + str(index)\n",
        "                output = conv2d(\n",
        "                    inputs=output,\n",
        "                    name=name,\n",
        "                    kernel_size=kernel_size,\n",
        "                    filters=kernel[0],\n",
        "                    strides=kernel[1],\n",
        "                    activation=tf.nn.leaky_relu,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                # save contracting path layers to be used for skip connections\n",
        "                layers.append(output)\n",
        "                \n",
        "                if kernel[2] > 0:\n",
        "                    keep_prob = 1.0 - kernel[2] if self.training else 1.0\n",
        "                    output = tf.nn.dropout(output, keep_prob=keep_prob, name='dropout_' + name, seed=seed)\n",
        "\n",
        "            # decoder branch\n",
        "            for index, kernel in enumerate(self.decoder_kernels):\n",
        "\n",
        "                name = 'deconv' + str(index)\n",
        "                output = conv2d_transpose(\n",
        "                    inputs=output,\n",
        "                    name=name,\n",
        "                    kernel_size=kernel_size,\n",
        "                    filters=kernel[0],\n",
        "                    strides=kernel[1],\n",
        "                    activation=tf.nn.relu,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                if kernel[2] > 0:\n",
        "                    keep_prob = 1.0 - kernel[2] if self.training else 1.0\n",
        "                    output = tf.nn.dropout(output, keep_prob=keep_prob, name='dropout_' + name, seed=seed)\n",
        "\n",
        "                # concat the layer from the contracting path with the output of the current layer\n",
        "                # concat only the channels (axis=3)\n",
        "                output = tf.concat([layers[len(layers) - index - 2], output], axis=3)\n",
        "\n",
        "            output = conv2d(\n",
        "                inputs=output,\n",
        "                name='conv_last',\n",
        "                filters=self.output_channels,   # number of output chanels\n",
        "                kernel_size=1,                  # last layer kernel size = 1\n",
        "                strides=1,                      # last layer stride = 1\n",
        "                bnorm=False,                    # do not use batch-norm for the last layer\n",
        "                activation=tf.nn.tanh,          # tanh activation function for the output\n",
        "                seed=seed\n",
        "            )\n",
        "\n",
        "            self.var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, self.name)\n",
        "\n",
        "            return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jDrR79EejSx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HRDWKR4ekgu"
      },
      "source": [
        "###Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnir6fgMem9v",
        "outputId": "7b177bd6-a023-4a48-eca5-0ba8cae6d98e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class Metrics():\n",
        "  def __init__(self):\n",
        "    self.test_data_path = '/content/drive/MyDrive/CV/checkpoints/samples'\n",
        "    self.gt_data_path = '/content/drive/MyDrive/CV/cifar10'\n",
        "    self.gt_data = []\n",
        "    self.test_data = []\n",
        "  def load_pickle(self,f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':\n",
        "        return  pickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return  pickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "  def load_CIFAR_batch(self,filename):\n",
        "    \"\"\" load single batch of cifar \"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        datadict = self.load_pickle(f)\n",
        "        X = datadict['data']\n",
        "        Y = datadict['labels']\n",
        "        X = X.reshape(10000,3072)\n",
        "        Y = np.array(Y)\n",
        "        return X, Y\n",
        "\n",
        "  def load_CIFAR10(self,ROOT):\n",
        "    \"\"\" load all of cifar \"\"\"\n",
        "    xs = []\n",
        "    ys = []\n",
        "    for b in range(1,6):\n",
        "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "        X, Y = self.load_CIFAR_batch(f)\n",
        "        xs.append(X)\n",
        "        ys.append(Y)\n",
        "    Xtr = np.concatenate(xs)\n",
        "    Ytr = np.concatenate(ys)\n",
        "    del X, Y\n",
        "    Xte, Yte = self.load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "    return Xtr, Ytr, Xte, Yte\n",
        "  def get_CIFAR10_data(self,num_training=50000, num_validation=0, num_test=10000):\n",
        "    # Load the raw CIFAR-10 data\n",
        "    cifar10_dir = self.gt_data_path\n",
        "    X_train, y_train, X_test, y_test = self.load_CIFAR10(cifar10_dir)\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    x_train = X_train.astype('float32')\n",
        "    x_test = X_test.astype('float32')\n",
        "\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    return x_train, y_train, X_val, y_val, x_test, y_test\n",
        "x = Metrics().get_CIFAR10_data()\n",
        "print(x[0][0].shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3072,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSpIwxlX0yxn"
      },
      "source": [
        "### Driver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ngYKG5r5y15h",
        "outputId": "1076b89b-ffc7-45d4-cc31-f036a3b913e1"
      },
      "source": [
        "# Driver\n",
        "\n",
        "# reset tensorflow graph\n",
        "tf.reset_default_graph()\n",
        "# initialize random seed\n",
        "tf.set_random_seed(options[\"seed\"])\n",
        "np.random.seed(options[\"seed\"])\n",
        "random.seed(options[\"seed\"])\n",
        "# create a session environment\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  if options[\"dataset\"] == 'CIFAR10_DATASET':\n",
        "    model = Cifar10Model(sess, options)\n",
        "\n",
        "  elif options[\"dataset\"] == 'PLACES365_DATASET':\n",
        "    model = Places365Model(sess, options)\n",
        "\n",
        "  if not os.path.exists(options[\"checkpoints_path\"]):\n",
        "    os.makedirs(options[\"checkpoints_path\"])\n",
        "\n",
        "  if options[\"log\"]:\n",
        "    open(model.train_log_file, 'w').close()\n",
        "    open(model.test_log_file, 'w').close()\n",
        "  # build the model and initialize\n",
        "  model.build()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  # load model only after global variables initialization\n",
        "  model.load()\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  #summary(model, (3, 512,1024))\n",
        "  print(model)\n",
        "\n",
        "  if options[\"mode\"] == 0:\n",
        "    args = options\n",
        "    print('\\n------------ Options -------------')\n",
        "    with open(os.path.join(options[\"checkpoints_path\"], 'options.dat'), 'w') as f:\n",
        "      for k, v in sorted(args.items()):\n",
        "        print('%s: %s' % (str(k), str(v)))\n",
        "        f.write('%s: %s\\n' % (str(k), str(v)))\n",
        "    print('-------------- End ----------------\\n') \n",
        "\n",
        "    model.train()\n",
        "      \n",
        "  elif options[\"mode\"] == 1:\n",
        "      model.test()\n",
        "  else:\n",
        "      model.turing_test()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're here??????\n",
            "Fuck me\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:308: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  '`tf.layers.batch_normalization` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/convolutional.py:1294: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "  warnings.warn('`tf.layers.conv2d_transpose` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loading model...\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/CV/checkpoints/CGAN_CIFAR10_DATASET\n",
            "<__main__.Cifar10Model object at 0x7fde50f66dd0>\n",
            "\n",
            "------------ Options -------------\n",
            "acc_thresh: 2.0\n",
            "augment: True\n",
            "batch_size: 60\n",
            "beta1: 0.0\n",
            "checkpoints_path: /content/drive/MyDrive/CV/checkpoints\n",
            "color_space: lab\n",
            "dataset: CIFAR10_DATASET\n",
            "dataset_path: /content/drive/MyDrive/CV/cifar10\n",
            "epochs: 10\n",
            "gpu_ids: 0\n",
            "l1_weight: 100.0\n",
            "label_smoothing: 1\n",
            "log: True\n",
            "log_interval: 834\n",
            "lr: 0.0003\n",
            "lr_decay: True\n",
            "lr_decay_rate: 0.1\n",
            "lr_decay_steps: 10000.0\n",
            "mode: 0\n",
            "name: ETF\n",
            "sample: True\n",
            "sample_interval: 1000\n",
            "sample_size: 8\n",
            "save: True\n",
            "save_interval: 1000\n",
            "seed: 100\n",
            "test_input: \n",
            "test_output: \n",
            "training: True\n",
            "turing_test_delay: 0\n",
            "turing_test_size: 100\n",
            "validate: True\n",
            "validate_interval: 10000\n",
            "visualize: True\n",
            "visualize_window: 100\n",
            "-------------- End ----------------\n",
            "\n",
            "Training epoch: 1 - learning rate: 1e-06\n",
            " 2605/50000 [>........................] - ETA: 4:22 - epoch: 1 - iter: 44 - step: 55044 - D loss: 1.3758 - D fake: 0.5973 - D real: 0.7785 - G loss: 4.9594 - G L1: 4.1601 - G gan: 0.7993 - accuracy: 0.3445"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: loadtxt: Empty input file: \"/content/drive/MyDrive/CV/checkpoints/log_test.dat\"\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "49438/50000 [=======================>.] - ETA: 2s - epoch: 1 - iter: 834 - step: 55834 - D loss: 1.3758 - D fake: 0.5975 - D real: 0.7782 - G loss: 4.9866 - G L1: 4.1875 - G gan: 0.7991 - accuracy: 0.3466\n",
            "\n",
            "Validating epoch: 1\n",
            " 9894/10000 [=======================>.] - ETA: 0s - D loss: 1.3758 - D fake: 0.5979 - D real: 0.7780 - G loss: 6.8673 - G L1: 6.0685 - G gan: 0.7987 - accuracy: 0.2205\n",
            "\n",
            "Training epoch: 2 - learning rate: 1e-06\n",
            " 2605/50000 [>........................] - ETA: 3:03 - epoch: 2 - iter: 44 - step: 55878 - D loss: 1.3759 - D fake: 0.5977 - D real: 0.7781 - G loss: 4.9596 - G L1: 4.1607 - G gan: 0.7989 - accuracy: 0.3453"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " 9830/50000 [===>.....................] - ETA: 2:37 - epoch: 2 - iter: 166 - step: 56000 - D loss: 1.3758 - D fake: 0.5977 - D real: 0.7781 - G loss: 4.9638 - G L1: 4.1649 - G gan: 0.7989 - accuracy: 0.3487\n",
            "saving sample CIFAR10_DATASET_56000.png - learning rate: 1e-06\n",
            "saving model...\n",
            "\n",
            "18260/50000 [========>................] - ETA: 2:05 - epoch: 2 - iter: 308 - step: 56142 - D loss: 1.3757 - D fake: 0.5975 - D real: 0.7782 - G loss: 4.9775 - G L1: 4.1784 - G gan: 0.7991 - accuracy: 0.3473"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}